{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2-Q1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE2R-tCbj2F1",
        "outputId": "c6db4a4f-c575-4fb2-b6a4-c0a68e113f54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Kevin Madden \n",
        "#Due Date: 2/28/2022\n",
        "#Professor: Dr. Hamed Tabkhi, PH.D.\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "#checking if I have GPU connected\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.A\n",
        "import csv\n",
        "housing_path = \"https://raw.githubusercontent.com/kmadden9/realTimeML/main/Housing_fixed.csv\"\n",
        "house_numpy = np.loadtxt(housing_path, dtype=np.float32, delimiter=\",\", skiprows=1)\n",
        "house_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSTHwS9ukTLS",
        "outputId": "9804b89a-61c5-402d-f6d6-effcb53ad7fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.330e+07, 7.420e+03, 4.000e+00, 2.000e+00, 3.000e+00, 2.000e+00],\n",
              "       [1.225e+07, 8.960e+03, 4.000e+00, 4.000e+00, 4.000e+00, 3.000e+00],\n",
              "       [1.225e+07, 9.960e+03, 3.000e+00, 2.000e+00, 2.000e+00, 2.000e+00],\n",
              "       ...,\n",
              "       [1.750e+06, 3.620e+03, 2.000e+00, 1.000e+00, 1.000e+00, 0.000e+00],\n",
              "       [1.750e+06, 2.910e+03, 3.000e+00, 1.000e+00, 1.000e+00, 0.000e+00],\n",
              "       [1.750e+06, 3.850e+03, 3.000e+00, 1.000e+00, 2.000e+00, 0.000e+00]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_list = next(csv.reader(open('/content/raw.githubusercontent.com/kmadden9/realTimeML/main/Housing_fixed.csv'), delimiter=','))\n",
        "house_numpy.shape, col_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BCDocIkkdd5",
        "outputId": "82c38dd9-b7cc-48ff-8594-fd919bdfb040"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((545, 6), ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house = torch.from_numpy(house_numpy)\n",
        "house.shape, house.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VAuEqL4kdqy",
        "outputId": "9b095a72-b988-4018-ac64-c8fed3eb455c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([545, 6]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = house[:, 1:]\n",
        "target = house[:, 0]\n",
        "data_mean = torch.mean(data, dim=0)\n",
        "data_var = torch.var(data, dim=0)\n",
        "target_mean = torch.mean(target, dim=0)\n",
        "target_var = torch.var(target, dim=0)\n",
        "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
        "target_normalized = (target - target_mean) / torch.sqrt(target_var)\n",
        "\n",
        "area = torch.stack(tuple(data_normalized[:,0]))\n",
        "bedrooms = torch.stack(tuple(data_normalized[:,1]))\n",
        "bathrooms = torch.stack(tuple(data_normalized[:,2]))\n",
        "stories = torch.stack(tuple(data_normalized[:,3]))\n",
        "parking = torch.stack(tuple(data_normalized[:,4]))"
      ],
      "metadata": {
        "id": "-DHwTV83kd1Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtljWIAAkd-I",
        "outputId": "74040347-bb4c-45ad-e2a3-1e50605be90b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13300000., 12250000., 12250000., 12215000., 11410000., 10850000.,\n",
              "        10150000., 10150000.,  9870000.,  9800000.,  9800000.,  9681000.,\n",
              "         9310000.,  9240000.,  9240000.,  9100000.,  9100000.,  8960000.,\n",
              "         8890000.,  8855000.,  8750000.,  8680000.,  8645000.,  8645000.,\n",
              "         8575000.,  8540000.,  8463000.,  8400000.,  8400000.,  8400000.,\n",
              "         8400000.,  8400000.,  8295000.,  8190000.,  8120000.,  8080940.,\n",
              "         8043000.,  7980000.,  7962500.,  7910000.,  7875000.,  7840000.,\n",
              "         7700000.,  7700000.,  7560000.,  7560000.,  7525000.,  7490000.,\n",
              "         7455000.,  7420000.,  7420000.,  7420000.,  7350000.,  7350000.,\n",
              "         7350000.,  7350000.,  7343000.,  7245000.,  7210000.,  7210000.,\n",
              "         7140000.,  7070000.,  7070000.,  7035000.,  7000000.,  6930000.,\n",
              "         6930000.,  6895000.,  6860000.,  6790000.,  6790000.,  6755000.,\n",
              "         6720000.,  6685000.,  6650000.,  6650000.,  6650000.,  6650000.,\n",
              "         6650000.,  6650000.,  6629000.,  6615000.,  6615000.,  6580000.,\n",
              "         6510000.,  6510000.,  6510000.,  6475000.,  6475000.,  6440000.,\n",
              "         6440000.,  6419000.,  6405000.,  6300000.,  6300000.,  6300000.,\n",
              "         6300000.,  6300000.,  6293000.,  6265000.,  6230000.,  6230000.,\n",
              "         6195000.,  6195000.,  6195000.,  6160000.,  6160000.,  6125000.,\n",
              "         6107500.,  6090000.,  6090000.,  6090000.,  6083000.,  6083000.,\n",
              "         6020000.,  6020000.,  6020000.,  5950000.,  5950000.,  5950000.,\n",
              "         5950000.,  5950000.,  5950000.,  5950000.,  5950000.,  5943000.,\n",
              "         5880000.,  5880000.,  5873000.,  5873000.,  5866000.,  5810000.,\n",
              "         5810000.,  5810000.,  5803000.,  5775000.,  5740000.,  5740000.,\n",
              "         5740000.,  5740000.,  5740000.,  5652500.,  5600000.,  5600000.,\n",
              "         5600000.,  5600000.,  5600000.,  5600000.,  5600000.,  5600000.,\n",
              "         5600000.,  5565000.,  5565000.,  5530000.,  5530000.,  5530000.,\n",
              "         5523000.,  5495000.,  5495000.,  5460000.,  5460000.,  5460000.,\n",
              "         5460000.,  5425000.,  5390000.,  5383000.,  5320000.,  5285000.,\n",
              "         5250000.,  5250000.,  5250000.,  5250000.,  5250000.,  5250000.,\n",
              "         5250000.,  5250000.,  5250000.,  5243000.,  5229000.,  5215000.,\n",
              "         5215000.,  5215000.,  5145000.,  5145000.,  5110000.,  5110000.,\n",
              "         5110000.,  5110000.,  5075000.,  5040000.,  5040000.,  5040000.,\n",
              "         5040000.,  5033000.,  5005000.,  4970000.,  4970000.,  4956000.,\n",
              "         4935000.,  4907000.,  4900000.,  4900000.,  4900000.,  4900000.,\n",
              "         4900000.,  4900000.,  4900000.,  4900000.,  4900000.,  4900000.,\n",
              "         4900000.,  4900000.,  4893000.,  4893000.,  4865000.,  4830000.,\n",
              "         4830000.,  4830000.,  4830000.,  4795000.,  4795000.,  4767000.,\n",
              "         4760000.,  4760000.,  4760000.,  4753000.,  4690000.,  4690000.,\n",
              "         4690000.,  4690000.,  4690000.,  4690000.,  4655000.,  4620000.,\n",
              "         4620000.,  4620000.,  4620000.,  4620000.,  4613000.,  4585000.,\n",
              "         4585000.,  4550000.,  4550000.,  4550000.,  4550000.,  4550000.,\n",
              "         4550000.,  4550000.,  4543000.,  4543000.,  4515000.,  4515000.,\n",
              "         4515000.,  4515000.,  4480000.,  4480000.,  4480000.,  4480000.,\n",
              "         4480000.,  4473000.,  4473000.,  4473000.,  4445000.,  4410000.,\n",
              "         4410000.,  4403000.,  4403000.,  4403000.,  4382000.,  4375000.,\n",
              "         4340000.,  4340000.,  4340000.,  4340000.,  4340000.,  4319000.,\n",
              "         4305000.,  4305000.,  4277000.,  4270000.,  4270000.,  4270000.,\n",
              "         4270000.,  4270000.,  4270000.,  4235000.,  4235000.,  4200000.,\n",
              "         4200000.,  4200000.,  4200000.,  4200000.,  4200000.,  4200000.,\n",
              "         4200000.,  4200000.,  4200000.,  4200000.,  4200000.,  4200000.,\n",
              "         4200000.,  4200000.,  4200000.,  4200000.,  4193000.,  4193000.,\n",
              "         4165000.,  4165000.,  4165000.,  4130000.,  4130000.,  4123000.,\n",
              "         4098500.,  4095000.,  4095000.,  4095000.,  4060000.,  4060000.,\n",
              "         4060000.,  4060000.,  4060000.,  4025000.,  4025000.,  4025000.,\n",
              "         4007500.,  4007500.,  3990000.,  3990000.,  3990000.,  3990000.,\n",
              "         3990000.,  3920000.,  3920000.,  3920000.,  3920000.,  3920000.,\n",
              "         3920000.,  3920000.,  3885000.,  3885000.,  3850000.,  3850000.,\n",
              "         3850000.,  3850000.,  3850000.,  3850000.,  3850000.,  3836000.,\n",
              "         3815000.,  3780000.,  3780000.,  3780000.,  3780000.,  3780000.,\n",
              "         3780000.,  3773000.,  3773000.,  3773000.,  3745000.,  3710000.,\n",
              "         3710000.,  3710000.,  3710000.,  3710000.,  3703000.,  3703000.,\n",
              "         3675000.,  3675000.,  3675000.,  3675000.,  3640000.,  3640000.,\n",
              "         3640000.,  3640000.,  3640000.,  3640000.,  3640000.,  3640000.,\n",
              "         3640000.,  3633000.,  3605000.,  3605000.,  3570000.,  3570000.,\n",
              "         3570000.,  3570000.,  3535000.,  3500000.,  3500000.,  3500000.,\n",
              "         3500000.,  3500000.,  3500000.,  3500000.,  3500000.,  3500000.,\n",
              "         3500000.,  3500000.,  3500000.,  3500000.,  3500000.,  3500000.,\n",
              "         3500000.,  3500000.,  3493000.,  3465000.,  3465000.,  3465000.,\n",
              "         3430000.,  3430000.,  3430000.,  3430000.,  3430000.,  3430000.,\n",
              "         3423000.,  3395000.,  3395000.,  3395000.,  3360000.,  3360000.,\n",
              "         3360000.,  3360000.,  3360000.,  3360000.,  3360000.,  3360000.,\n",
              "         3353000.,  3332000.,  3325000.,  3325000.,  3290000.,  3290000.,\n",
              "         3290000.,  3290000.,  3290000.,  3290000.,  3290000.,  3290000.,\n",
              "         3255000.,  3255000.,  3234000.,  3220000.,  3220000.,  3220000.,\n",
              "         3220000.,  3150000.,  3150000.,  3150000.,  3150000.,  3150000.,\n",
              "         3150000.,  3150000.,  3150000.,  3150000.,  3143000.,  3129000.,\n",
              "         3118850.,  3115000.,  3115000.,  3115000.,  3087000.,  3080000.,\n",
              "         3080000.,  3080000.,  3080000.,  3045000.,  3010000.,  3010000.,\n",
              "         3010000.,  3010000.,  3010000.,  3010000.,  3010000.,  3003000.,\n",
              "         2975000.,  2961000.,  2940000.,  2940000.,  2940000.,  2940000.,\n",
              "         2940000.,  2940000.,  2940000.,  2940000.,  2870000.,  2870000.,\n",
              "         2870000.,  2870000.,  2852500.,  2835000.,  2835000.,  2835000.,\n",
              "         2800000.,  2800000.,  2730000.,  2730000.,  2695000.,  2660000.,\n",
              "         2660000.,  2660000.,  2660000.,  2660000.,  2660000.,  2660000.,\n",
              "         2653000.,  2653000.,  2604000.,  2590000.,  2590000.,  2590000.,\n",
              "         2520000.,  2520000.,  2520000.,  2485000.,  2485000.,  2450000.,\n",
              "         2450000.,  2450000.,  2450000.,  2450000.,  2450000.,  2408000.,\n",
              "         2380000.,  2380000.,  2380000.,  2345000.,  2310000.,  2275000.,\n",
              "         2275000.,  2275000.,  2240000.,  2233000.,  2135000.,  2100000.,\n",
              "         2100000.,  2100000.,  1960000.,  1890000.,  1890000.,  1855000.,\n",
              "         1820000.,  1767150.,  1750000.,  1750000.,  1750000.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = target.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "train_indices, val_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI0aAnxFBgZo",
        "outputId": "68e4169c-e8e1-458b-96d7-ca59e4aeaa5d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([111, 504, 468, 240, 146,  31, 186, 364, 475, 250,  15, 264, 120, 442,\n",
              "          89, 387, 180, 484, 375,  48,   4, 355, 301,  42, 306, 535, 476, 185,\n",
              "         427, 234, 181,   6, 156,  57, 533, 405, 456, 270, 448,  50, 434, 487,\n",
              "         490, 374, 299, 518, 276, 150, 478, 473, 522, 105, 324, 457,  56, 187,\n",
              "         510, 444, 261, 542,  12,   9, 340, 233, 412, 483,  87, 297, 328, 397,\n",
              "         227, 226, 417, 349, 486, 117, 342,  55,  41, 279, 193, 443, 127, 426,\n",
              "         508, 329, 275, 410, 148, 123,  77, 303,  66, 513,  60, 500, 164, 360,\n",
              "         289, 235, 296, 361, 350, 175, 119, 334, 317, 286, 525, 160,  28, 222,\n",
              "         493, 454, 113, 316, 403, 523, 404, 116, 356, 414, 159,   5,  46,  97,\n",
              "         248, 371, 437, 332, 241, 314, 194,  64, 394, 528,  69, 197, 424, 529,\n",
              "         330, 256,  30,  62, 101,  45, 411, 441, 224, 173, 331, 368, 196, 362,\n",
              "         265, 345, 452,   1, 280, 214, 492, 198, 106, 358, 450, 191, 536,  16,\n",
              "         449, 353, 165, 451, 540,  73, 122, 271,  54, 309, 497, 308, 285, 392,\n",
              "         231, 389, 129, 385, 465, 400, 109, 293, 521, 333,  17, 423, 282, 104,\n",
              "         524,  84, 409, 544, 347, 505, 199,  14,  29, 399, 273, 445, 491, 453,\n",
              "          63, 348, 336,  78, 481,   2,  27, 433, 464, 413, 381, 138, 189, 538,\n",
              "         202, 294, 402, 238, 469, 168, 223, 396, 494, 143,   8, 471, 281,  61,\n",
              "         357, 277, 182, 126,  23, 278, 479, 145,  93, 366, 435, 543, 384, 310,\n",
              "         436, 211, 141, 298, 210, 213,  86, 516, 183, 526,  75, 255, 291, 218,\n",
              "         382, 365, 247, 152,  88,  21, 244,  85, 288, 354, 125, 209, 140, 421,\n",
              "          72, 370,  51, 260, 230, 292,  38, 415, 315, 178, 232, 305,  65, 176,\n",
              "         541,  33, 161,  20, 243,  92, 406,  49, 420, 128, 395,  40, 249, 431,\n",
              "         532,  34, 121, 514,  43, 503, 208, 527, 363,  81, 488, 440, 131,  71,\n",
              "          74, 337, 311, 520, 386,  98, 408, 284,  68,   7, 530, 509, 390, 422,\n",
              "         295, 133,  37,  80, 151, 460, 380, 376, 130, 114, 195, 112, 377, 216,\n",
              "          39,  19, 153, 103,  91, 239, 383, 511, 470, 217,  52, 124, 300, 519,\n",
              "         212, 388, 192, 393, 438,  96, 304, 258, 312, 220, 346, 455, 446, 359,\n",
              "         205, 162,  22, 219, 512, 537, 313, 416, 179, 242, 432, 100, 462,  67,\n",
              "         245,  94, 320,  47, 283,  59, 102, 322, 274, 307, 496,   0, 430,  82,\n",
              "         447, 419, 203, 147, 459, 272, 325, 506, 477, 142, 268,  10, 200, 287,\n",
              "          58,  95, 343, 466, 489, 259,  35,  79, 174, 172, 463, 170, 474, 251,\n",
              "         344, 204]),\n",
              " tensor([498, 163, 326, 139, 136, 379, 134, 137, 495, 155, 169, 429, 302, 458,\n",
              "         207, 425, 263,  90,  11, 485, 369, 401, 253, 254, 132, 118,  26, 108,\n",
              "         517, 246,  24, 327, 428, 177, 539, 351, 472, 188, 319, 323, 236, 378,\n",
              "         167, 201, 290,  25,  32, 391, 269,  13,   3, 373, 499,  18, 461, 502,\n",
              "         482, 398, 267, 229,  83, 262, 367, 507, 439, 135, 158, 144, 352, 206,\n",
              "         257, 515, 318,  44, 501, 149, 225,  76, 215, 335,  53, 467, 115, 184,\n",
              "         321, 190, 228, 418, 166,  70, 157, 221, 372, 154, 339, 407, 341,  36,\n",
              "         531, 171, 237, 338, 480, 252, 107, 534,  99, 110, 266]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_area = area[train_indices]\n",
        "train_bedrooms = bedrooms[train_indices]\n",
        "train_bathrooms = bathrooms[train_indices]\n",
        "train_stories = stories[train_indices]\n",
        "train_parking = parking[train_indices]\n",
        "\n",
        "train_data = data_normalized[train_indices]\n",
        "train_price = target_normalized[train_indices]\n",
        "\n",
        "eval_area = area[val_indices]\n",
        "eval_bedrooms = bedrooms[val_indices]\n",
        "eval_bathrooms = bathrooms[val_indices]\n",
        "eval_stories = stories[val_indices]\n",
        "eval_parking = parking[val_indices]\n",
        "\n",
        "eval_data = data_normalized[val_indices]\n",
        "eval_price = target_normalized[val_indices]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4M8trgDFBseZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(area, bedrooms, bathrooms, stories, parking, w1, w2, w3, w4, w5, b):\n",
        "  return w5 * area + w4 * bedrooms + w3 * bathrooms + w2 * stories + w1 * parking + b"
      ],
      "metadata": {
        "id": "pgUU99t2C-Kh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(price_pred, target_normalized):\n",
        "  squared_diffs = (price_pred - target_normalized)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "fRMhMhSLEci0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params], lr=learning_rate)"
      ],
      "metadata": {
        "id": "1YegQL2KEc7i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_pred = model(area, bedrooms, bathrooms, stories, parking, *params)\n",
        "loss = loss_fn(price_pred, target_normalized)\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgdOgq1zEgHv",
        "outputId": "fce69501-5378-4e41-8149-776a4158987a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9998e-01, 3.0920e-12],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "price_train = model(train_area, train_bedrooms, train_bathrooms, train_stories, train_parking, *params)\n",
        "train_loss = loss_fn(price_train, train_price)\n",
        "\n",
        "price_eval = model(eval_area, eval_bedrooms, eval_bathrooms, eval_stories, eval_parking, *params)\n",
        "eval_loss = loss_fn(price_eval, eval_price)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "train_loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIgIw2O2EjtM",
        "outputId": "8f416772-711a-4401-edf8-9fd65affdf88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.7378e-01, 9.6874e-01, 9.6824e-01, 9.6480e-01, 9.7262e-01, 4.9346e-04],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_area, train_bedrooms, train_bathrooms, train_stories, train_parking, train_price,\n",
        "                  eval_area, eval_bedrooms, eval_bathrooms, eval_stories, eval_parking, eval_price):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    price_train = model(train_area, train_bedrooms, train_bathrooms, train_stories, train_parking, *params)\n",
        "    train_loss = loss_fn(price_train, train_price)\n",
        "\n",
        "    price_eval = model(eval_area, eval_bedrooms, eval_bathrooms, eval_stories, eval_parking, *params)\n",
        "    eval_loss = loss_fn(price_eval, eval_price)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch <= 3 or epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "        f\" Validation loss {eval_loss.item():.4f}\")\n",
        "  \n",
        "  return params"
      ],
      "metadata": {
        "id": "UHjTYhLhEpfH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.b\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = .001\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 5000,\n",
        "  optimizer = optimizer,\n",
        "  params = params,\n",
        "  train_area = train_area,\n",
        "  train_bedrooms = train_bedrooms,\n",
        "  train_bathrooms = train_bathrooms,\n",
        "  train_stories = train_stories,\n",
        "  train_parking = train_parking,\n",
        "  train_price = train_price,\n",
        "  eval_area = eval_area,\n",
        "  eval_bedrooms = eval_bedrooms,\n",
        "  eval_bathrooms = eval_bathrooms,\n",
        "  eval_stories = eval_stories,\n",
        "  eval_parking = eval_parking,\n",
        "  eval_price = eval_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODYaFdUFEt-N",
        "outputId": "a3dfe679-884d-4e68-a0c0-707fda87cd67"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 6.2892, Validation loss 5.0726\n",
            "Epoch 2, Training loss 6.2426, Validation loss 5.0360\n",
            "Epoch 3, Training loss 6.1965, Validation loss 4.9996\n",
            "Epoch 500, Training loss 0.5568, Validation loss 0.5584\n",
            "Epoch 1000, Training loss 0.4426, Validation loss 0.4609\n",
            "Epoch 1500, Training loss 0.4377, Validation loss 0.4516\n",
            "Epoch 2000, Training loss 0.4368, Validation loss 0.4480\n",
            "Epoch 2500, Training loss 0.4365, Validation loss 0.4462\n",
            "Epoch 3000, Training loss 0.4364, Validation loss 0.4454\n",
            "Epoch 3500, Training loss 0.4364, Validation loss 0.4449\n",
            "Epoch 4000, Training loss 0.4364, Validation loss 0.4447\n",
            "Epoch 4500, Training loss 0.4364, Validation loss 0.4446\n",
            "Epoch 5000, Training loss 0.4364, Validation loss 0.4445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1907,  0.2514,  0.2958,  0.0650,  0.3734, -0.0071],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "linear_model = nn.Linear(5, 1)\n",
        "linear_model(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKZN__zLG3wT",
        "outputId": "89d3c574-43fd-43c6-c21d-671e5b76e591"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-7.5114e-01],\n",
              "        [-2.2938e+00],\n",
              "        [-5.6899e-02],\n",
              "        [-5.5617e-01],\n",
              "        [ 2.1855e-01],\n",
              "        [-1.2069e+00],\n",
              "        [-1.5605e+00],\n",
              "        [-8.1923e-01],\n",
              "        [ 3.1253e-01],\n",
              "        [-9.0250e-01],\n",
              "        [ 1.2808e+00],\n",
              "        [-1.7574e+00],\n",
              "        [-8.9563e-01],\n",
              "        [-1.2131e+00],\n",
              "        [-5.6359e-01],\n",
              "        [ 2.2292e-02],\n",
              "        [-8.8872e-01],\n",
              "        [-4.1834e-01],\n",
              "        [-7.9769e-01],\n",
              "        [-6.5024e-01],\n",
              "        [ 5.3464e-02],\n",
              "        [-3.6474e-01],\n",
              "        [ 5.4473e-01],\n",
              "        [-9.0731e-01],\n",
              "        [-2.1722e-01],\n",
              "        [-7.9293e-01],\n",
              "        [-9.7203e-01],\n",
              "        [ 6.5875e-01],\n",
              "        [-8.6142e-01],\n",
              "        [-1.0408e+00],\n",
              "        [-5.6001e-01],\n",
              "        [ 2.6420e-01],\n",
              "        [-1.1264e+00],\n",
              "        [-1.6037e+00],\n",
              "        [-2.2906e-01],\n",
              "        [-6.2566e-01],\n",
              "        [-5.8329e-01],\n",
              "        [-6.1260e-01],\n",
              "        [ 1.2599e-01],\n",
              "        [-1.1313e+00],\n",
              "        [ 1.5350e-01],\n",
              "        [-9.2227e-01],\n",
              "        [-6.9752e-01],\n",
              "        [-1.0272e+00],\n",
              "        [-1.1313e+00],\n",
              "        [-8.9220e-01],\n",
              "        [-8.6795e-01],\n",
              "        [ 3.1300e-01],\n",
              "        [-9.4324e-01],\n",
              "        [-5.3352e-01],\n",
              "        [-6.6893e-01],\n",
              "        [ 6.6828e-02],\n",
              "        [-1.1313e+00],\n",
              "        [-8.8134e-01],\n",
              "        [-7.0829e-01],\n",
              "        [ 1.8157e-01],\n",
              "        [ 6.7006e-01],\n",
              "        [-7.1668e-01],\n",
              "        [-8.9912e-01],\n",
              "        [-8.6795e-01],\n",
              "        [-7.0829e-01],\n",
              "        [ 9.2280e-01],\n",
              "        [-9.3848e-01],\n",
              "        [-8.9764e-01],\n",
              "        [ 9.7663e-01],\n",
              "        [-3.1025e-01],\n",
              "        [ 1.5199e+00],\n",
              "        [-2.8942e-01],\n",
              "        [ 2.6140e-01],\n",
              "        [-2.5878e-02],\n",
              "        [-1.0888e+00],\n",
              "        [-1.2354e+00],\n",
              "        [-2.1762e-01],\n",
              "        [-6.2574e-01],\n",
              "        [-8.9317e-02],\n",
              "        [-1.3162e+00],\n",
              "        [-8.3415e-01],\n",
              "        [-8.2309e-01],\n",
              "        [ 3.2402e-01],\n",
              "        [-8.9220e-01],\n",
              "        [ 1.8157e-01],\n",
              "        [-9.8470e-01],\n",
              "        [-6.5189e-03],\n",
              "        [-9.7203e-01],\n",
              "        [-2.3932e-02],\n",
              "        [-5.8123e-01],\n",
              "        [ 9.0257e-02],\n",
              "        [ 8.3540e-02],\n",
              "        [ 5.6036e-01],\n",
              "        [-1.6642e+00],\n",
              "        [-6.0720e-02],\n",
              "        [ 7.3250e-01],\n",
              "        [-1.1379e+00],\n",
              "        [-2.5444e-01],\n",
              "        [-1.1313e+00],\n",
              "        [-9.4663e-01],\n",
              "        [ 6.7603e-01],\n",
              "        [ 3.1668e-01],\n",
              "        [-8.0927e-01],\n",
              "        [-2.6570e-01],\n",
              "        [-6.4961e-01],\n",
              "        [ 3.2637e-02],\n",
              "        [-9.3705e-01],\n",
              "        [-8.4383e-01],\n",
              "        [-5.9348e-01],\n",
              "        [-2.8948e-01],\n",
              "        [-1.0719e+00],\n",
              "        [ 5.5705e-02],\n",
              "        [-5.4308e-01],\n",
              "        [-8.8665e-01],\n",
              "        [ 4.4841e-01],\n",
              "        [ 5.3365e-01],\n",
              "        [-1.8374e+00],\n",
              "        [ 8.6580e-01],\n",
              "        [ 7.3941e-01],\n",
              "        [ 6.4190e-01],\n",
              "        [-6.0815e-01],\n",
              "        [-5.0375e-01],\n",
              "        [ 2.1537e-01],\n",
              "        [ 5.0646e-01],\n",
              "        [ 4.4012e-01],\n",
              "        [ 2.4762e-01],\n",
              "        [-8.5671e-01],\n",
              "        [-8.9330e-01],\n",
              "        [-7.9539e-01],\n",
              "        [ 1.6923e+00],\n",
              "        [ 5.2581e-01],\n",
              "        [-8.2309e-01],\n",
              "        [ 3.2637e-02],\n",
              "        [ 9.6044e-01],\n",
              "        [-8.5312e-03],\n",
              "        [-3.6931e-01],\n",
              "        [-1.1291e-01],\n",
              "        [-1.6819e-01],\n",
              "        [ 5.0369e-01],\n",
              "        [-9.7203e-01],\n",
              "        [-9.5049e-01],\n",
              "        [-2.6975e-01],\n",
              "        [-1.4055e-01],\n",
              "        [ 4.1524e-01],\n",
              "        [-9.9967e-01],\n",
              "        [-8.8043e-01],\n",
              "        [-3.4971e-01],\n",
              "        [-1.5848e+00],\n",
              "        [-2.6146e-01],\n",
              "        [-2.2038e-01],\n",
              "        [ 1.1467e+00],\n",
              "        [-7.7739e-01],\n",
              "        [ 4.7413e-02],\n",
              "        [-9.1297e-01],\n",
              "        [-4.1924e-02],\n",
              "        [-1.9884e-01],\n",
              "        [-5.3216e-01],\n",
              "        [-2.0754e+00],\n",
              "        [-9.2899e-01],\n",
              "        [-5.1055e-01],\n",
              "        [ 2.8171e-01],\n",
              "        [-1.4116e+00],\n",
              "        [ 6.3914e-01],\n",
              "        [-1.1264e+00],\n",
              "        [-3.1651e-01],\n",
              "        [ 1.1479e-02],\n",
              "        [-9.9281e-01],\n",
              "        [ 2.7134e-01],\n",
              "        [-6.1016e-01],\n",
              "        [-6.7034e-01],\n",
              "        [ 6.1426e-01],\n",
              "        [-4.5450e-01],\n",
              "        [-4.2636e-01],\n",
              "        [-1.0011e+00],\n",
              "        [-8.0164e-01],\n",
              "        [ 8.5141e-01],\n",
              "        [ 6.1735e-01],\n",
              "        [-1.0926e+00],\n",
              "        [-1.2249e-01],\n",
              "        [-3.4237e-01],\n",
              "        [ 7.1377e-01],\n",
              "        [ 1.6423e-01],\n",
              "        [ 5.1544e-01],\n",
              "        [-9.9395e-01],\n",
              "        [-9.9505e-01],\n",
              "        [ 3.4742e-01],\n",
              "        [-2.8047e-01],\n",
              "        [ 5.3505e-01],\n",
              "        [-1.2270e+00],\n",
              "        [-3.3714e-01],\n",
              "        [ 1.0886e+00],\n",
              "        [ 1.7114e-01],\n",
              "        [ 3.0215e-01],\n",
              "        [ 8.0688e-02],\n",
              "        [ 2.4342e-01],\n",
              "        [ 7.2707e-01],\n",
              "        [ 2.4024e-01],\n",
              "        [ 2.5483e-01],\n",
              "        [-4.3539e-01],\n",
              "        [-1.9772e+00],\n",
              "        [ 3.9034e-01],\n",
              "        [-1.1506e+00],\n",
              "        [ 7.0301e-02],\n",
              "        [-6.7204e-02],\n",
              "        [-1.2706e-01],\n",
              "        [-1.8580e-01],\n",
              "        [ 2.6493e-01],\n",
              "        [-2.6880e-01],\n",
              "        [-1.2677e-02],\n",
              "        [ 4.0695e-01],\n",
              "        [ 3.9304e-01],\n",
              "        [-3.3714e-01],\n",
              "        [-4.2111e-01],\n",
              "        [ 2.5683e-01],\n",
              "        [ 9.8520e-02],\n",
              "        [ 1.3191e+00],\n",
              "        [-1.2241e+00],\n",
              "        [-1.1348e+00],\n",
              "        [ 1.9264e-01],\n",
              "        [-2.5664e-01],\n",
              "        [ 3.7101e-01],\n",
              "        [ 4.0479e-01],\n",
              "        [ 2.5690e-01],\n",
              "        [ 2.1570e-01],\n",
              "        [ 1.5287e-01],\n",
              "        [-1.4323e+00],\n",
              "        [ 1.0664e+00],\n",
              "        [ 2.2594e-01],\n",
              "        [ 1.2148e+00],\n",
              "        [ 7.9374e-01],\n",
              "        [-1.9689e-01],\n",
              "        [ 5.2476e-01],\n",
              "        [-4.1899e-02],\n",
              "        [-4.6484e-01],\n",
              "        [ 2.5793e-01],\n",
              "        [-7.4871e-02],\n",
              "        [-2.3417e-01],\n",
              "        [-9.6984e-02],\n",
              "        [-8.9720e-01],\n",
              "        [ 1.3734e-01],\n",
              "        [-9.1741e-02],\n",
              "        [-5.9338e-02],\n",
              "        [-1.2817e+00],\n",
              "        [-9.4845e-02],\n",
              "        [-1.1696e-01],\n",
              "        [ 5.5898e-02],\n",
              "        [-2.4868e-01],\n",
              "        [-3.9933e-01],\n",
              "        [-1.6493e-02],\n",
              "        [ 1.9720e-01],\n",
              "        [-1.8544e-01],\n",
              "        [ 2.9841e-01],\n",
              "        [-7.3177e-01],\n",
              "        [-1.2153e+00],\n",
              "        [-3.4648e-01],\n",
              "        [-1.7086e-01],\n",
              "        [ 6.9080e-01],\n",
              "        [-1.9060e-03],\n",
              "        [-1.8364e-01],\n",
              "        [ 5.0887e-01],\n",
              "        [ 9.2375e-03],\n",
              "        [ 4.6829e-01],\n",
              "        [-8.9317e-02],\n",
              "        [ 5.7452e-01],\n",
              "        [-2.1066e-01],\n",
              "        [-2.6665e-01],\n",
              "        [ 1.0971e-01],\n",
              "        [-2.0335e-01],\n",
              "        [ 1.8882e-01],\n",
              "        [-3.5372e-01],\n",
              "        [ 2.1069e-01],\n",
              "        [ 3.2306e-02],\n",
              "        [-3.3099e-01],\n",
              "        [-2.1275e-01],\n",
              "        [-9.9543e-01],\n",
              "        [-1.0152e+00],\n",
              "        [ 9.9433e-02],\n",
              "        [-3.2323e-01],\n",
              "        [-1.2368e-01],\n",
              "        [ 1.4869e-01],\n",
              "        [ 3.0363e-01],\n",
              "        [ 1.1273e+00],\n",
              "        [-7.3687e-02],\n",
              "        [ 4.7044e-01],\n",
              "        [ 3.9060e-01],\n",
              "        [ 4.2153e-01],\n",
              "        [-4.5116e-01],\n",
              "        [-4.1253e-01],\n",
              "        [ 7.6939e-01],\n",
              "        [ 1.6732e-01],\n",
              "        [-2.8674e-01],\n",
              "        [ 8.3841e-03],\n",
              "        [-5.5192e-02],\n",
              "        [ 6.0811e-01],\n",
              "        [-2.4341e+00],\n",
              "        [-3.4363e-01],\n",
              "        [-1.5253e+00],\n",
              "        [ 3.0501e-01],\n",
              "        [-1.3521e+00],\n",
              "        [-4.3043e-01],\n",
              "        [-9.0178e-01],\n",
              "        [-1.1385e+00],\n",
              "        [ 3.3784e-01],\n",
              "        [ 6.0777e-01],\n",
              "        [-2.6784e-01],\n",
              "        [-2.6527e-01],\n",
              "        [-4.3105e-01],\n",
              "        [-4.9994e-02],\n",
              "        [ 7.8053e-01],\n",
              "        [-1.7086e-01],\n",
              "        [ 2.1250e-02],\n",
              "        [ 2.0294e-02],\n",
              "        [-8.8488e-02],\n",
              "        [-3.7494e-01],\n",
              "        [ 1.5525e-01],\n",
              "        [ 5.3306e-01],\n",
              "        [-1.7438e-01],\n",
              "        [-1.1330e+00],\n",
              "        [ 1.7404e-01],\n",
              "        [ 3.6540e-01],\n",
              "        [-9.8547e-01],\n",
              "        [-7.4352e-01],\n",
              "        [-7.2107e-02],\n",
              "        [-4.7216e-01],\n",
              "        [ 5.3464e-02],\n",
              "        [-9.3176e-01],\n",
              "        [-9.7950e-01],\n",
              "        [ 3.8664e-01],\n",
              "        [-1.2982e-01],\n",
              "        [-5.3692e-01],\n",
              "        [-3.6864e-01],\n",
              "        [ 2.4791e-01],\n",
              "        [-1.0197e+00],\n",
              "        [-2.0446e-01],\n",
              "        [ 7.1344e-02],\n",
              "        [-2.4615e-01],\n",
              "        [-2.5498e-01],\n",
              "        [-3.3714e-01],\n",
              "        [ 1.5022e-01],\n",
              "        [ 3.2700e-01],\n",
              "        [ 6.5296e-01],\n",
              "        [-1.5287e+00],\n",
              "        [ 3.4028e-02],\n",
              "        [-1.4655e+00],\n",
              "        [-1.4358e+00],\n",
              "        [-6.5076e-01],\n",
              "        [ 2.3670e-01],\n",
              "        [ 1.5532e-01],\n",
              "        [ 1.2353e-01],\n",
              "        [-4.7327e-01],\n",
              "        [-1.8766e-01],\n",
              "        [-2.8876e-01],\n",
              "        [-8.6307e-01],\n",
              "        [-8.5597e-02],\n",
              "        [ 8.8356e-02],\n",
              "        [ 8.8981e-02],\n",
              "        [ 6.0535e-01],\n",
              "        [-4.3687e-01],\n",
              "        [ 8.5646e-01],\n",
              "        [ 6.7645e-01],\n",
              "        [-1.6361e+00],\n",
              "        [ 4.6743e-02],\n",
              "        [ 7.2396e-02],\n",
              "        [-7.0298e-02],\n",
              "        [ 1.4979e-01],\n",
              "        [ 1.6008e-01],\n",
              "        [ 1.5117e-01],\n",
              "        [ 8.6770e-02],\n",
              "        [-3.2055e-01],\n",
              "        [ 3.4467e-01],\n",
              "        [ 9.3127e-02],\n",
              "        [ 9.3127e-02],\n",
              "        [ 3.7093e-01],\n",
              "        [ 8.8981e-02],\n",
              "        [ 3.9113e-01],\n",
              "        [-2.5836e-01],\n",
              "        [-3.1226e-01],\n",
              "        [-7.3774e-02],\n",
              "        [-8.1193e-01],\n",
              "        [ 7.1960e-02],\n",
              "        [-8.6265e-01],\n",
              "        [-1.2477e+00],\n",
              "        [-5.1717e-01],\n",
              "        [ 2.2728e-02],\n",
              "        [ 2.1337e-01],\n",
              "        [ 1.4426e-01],\n",
              "        [-3.1640e-01],\n",
              "        [-1.0749e+00],\n",
              "        [ 2.1337e-01],\n",
              "        [ 9.4509e-02],\n",
              "        [ 6.8337e-02],\n",
              "        [-1.6576e-01],\n",
              "        [-2.4730e-01],\n",
              "        [-3.7936e-01],\n",
              "        [-1.3465e+00],\n",
              "        [-3.3216e-01],\n",
              "        [-2.0031e-01],\n",
              "        [ 3.5413e-01],\n",
              "        [-1.9097e-01],\n",
              "        [-9.4021e-01],\n",
              "        [ 1.9859e-01],\n",
              "        [ 5.1094e-01],\n",
              "        [-2.1647e-01],\n",
              "        [ 7.1134e-01],\n",
              "        [ 1.8090e-01],\n",
              "        [ 8.7346e-01],\n",
              "        [ 4.0410e-01],\n",
              "        [ 1.1170e+00],\n",
              "        [-7.4541e-02],\n",
              "        [-2.4901e-01],\n",
              "        [ 4.3078e-01],\n",
              "        [-5.3513e-01],\n",
              "        [ 1.4426e-01],\n",
              "        [ 2.3979e-01],\n",
              "        [-1.3983e-01],\n",
              "        [-5.3513e-01],\n",
              "        [-3.9104e-01],\n",
              "        [-1.3721e+00],\n",
              "        [ 1.4979e-01],\n",
              "        [ 1.3648e-02],\n",
              "        [ 1.3053e-02],\n",
              "        [ 9.4509e-02],\n",
              "        [-3.2323e-01],\n",
              "        [-4.0944e-01],\n",
              "        [ 8.1019e-02],\n",
              "        [ 2.4792e-01],\n",
              "        [ 1.0557e-01],\n",
              "        [-1.5365e-01],\n",
              "        [-3.2332e-01],\n",
              "        [ 2.3979e-01],\n",
              "        [-2.9877e-01],\n",
              "        [-4.5530e-01],\n",
              "        [ 2.5388e-01],\n",
              "        [-3.5518e-01],\n",
              "        [-6.3048e-02],\n",
              "        [-5.7562e-01],\n",
              "        [ 1.6561e-01],\n",
              "        [-4.3008e-01],\n",
              "        [-4.9104e-01],\n",
              "        [ 1.4979e-01],\n",
              "        [-4.5530e-01],\n",
              "        [ 2.4482e-01],\n",
              "        [ 2.1337e-01],\n",
              "        [ 1.3459e-01],\n",
              "        [-5.1204e-01],\n",
              "        [-1.4779e-01],\n",
              "        [ 6.6465e-02],\n",
              "        [ 2.9212e-02],\n",
              "        [-3.2055e-01],\n",
              "        [ 3.3161e-01],\n",
              "        [-6.4344e-01],\n",
              "        [ 7.5160e-02],\n",
              "        [ 3.6556e-01],\n",
              "        [-5.2372e-01],\n",
              "        [-2.7494e-01],\n",
              "        [ 5.2434e-01],\n",
              "        [ 7.0028e-01],\n",
              "        [ 1.1968e-01],\n",
              "        [-1.2982e-01],\n",
              "        [ 8.7523e-02],\n",
              "        [-3.4051e-01],\n",
              "        [-2.5731e-01],\n",
              "        [-2.1966e-01],\n",
              "        [ 7.5160e-02],\n",
              "        [ 8.1500e-01],\n",
              "        [ 2.7694e-01],\n",
              "        [-4.5323e-01],\n",
              "        [ 1.8495e-02],\n",
              "        [ 2.3762e-01],\n",
              "        [ 1.1662e-01],\n",
              "        [-3.2470e-01],\n",
              "        [-9.5801e-02],\n",
              "        [-1.6748e-02],\n",
              "        [ 2.2719e-01],\n",
              "        [ 2.9614e-02],\n",
              "        [-2.3348e-01],\n",
              "        [-2.0118e-01],\n",
              "        [ 7.0401e-01],\n",
              "        [-3.0956e-01],\n",
              "        [-7.3774e-02],\n",
              "        [ 1.6084e-01],\n",
              "        [ 2.7694e-01],\n",
              "        [-1.5013e-01],\n",
              "        [-5.0928e-01],\n",
              "        [-1.6671e-01],\n",
              "        [-3.5406e-02],\n",
              "        [-3.1640e-01],\n",
              "        [ 1.6249e-01],\n",
              "        [ 1.1584e-02],\n",
              "        [ 9.3127e-02],\n",
              "        [ 4.2068e-01],\n",
              "        [-2.6880e-01],\n",
              "        [-3.7627e-01],\n",
              "        [-1.9159e-01],\n",
              "        [-4.6472e-02],\n",
              "        [ 6.0384e-02],\n",
              "        [-2.8143e-01],\n",
              "        [-1.2463e-01],\n",
              "        [ 5.3125e-01],\n",
              "        [-9.4845e-02],\n",
              "        [ 1.4426e-01],\n",
              "        [ 1.3514e-01],\n",
              "        [-2.1198e-01],\n",
              "        [-2.0298e+00],\n",
              "        [-2.8495e-01],\n",
              "        [-3.3608e-01],\n",
              "        [ 1.7648e-01],\n",
              "        [-1.1910e-01],\n",
              "        [ 3.1625e-02],\n",
              "        [-1.9893e-01],\n",
              "        [-6.3826e-03],\n",
              "        [ 8.8981e-02],\n",
              "        [ 1.9955e-01],\n",
              "        [-7.7662e-01],\n",
              "        [-2.7389e-01],\n",
              "        [-2.3243e-01],\n",
              "        [-7.3774e-02],\n",
              "        [-1.4364e-01],\n",
              "        [-3.3714e-01],\n",
              "        [-3.0811e-01],\n",
              "        [ 1.4331e-01],\n",
              "        [ 1.1014e-01],\n",
              "        [ 7.5160e-02],\n",
              "        [ 1.8053e-01],\n",
              "        [ 6.5563e-01],\n",
              "        [ 9.3818e-02],\n",
              "        [-4.0970e-01],\n",
              "        [-1.5198e+00],\n",
              "        [ 4.2543e-02],\n",
              "        [ 9.4509e-02],\n",
              "        [ 3.0934e-02],\n",
              "        [-1.5482e-01],\n",
              "        [ 4.0348e-01],\n",
              "        [-2.0307e-01],\n",
              "        [-4.0242e-01],\n",
              "        [ 6.0573e-02],\n",
              "        [ 6.0561e-03],\n",
              "        [-4.2006e-01],\n",
              "        [-6.0050e-01],\n",
              "        [ 1.5989e-01],\n",
              "        [-8.0581e-01],\n",
              "        [-5.1681e-01],\n",
              "        [ 9.5753e-02],\n",
              "        [ 1.0876e-01],\n",
              "        [ 2.1422e-01],\n",
              "        [-3.4023e-01],\n",
              "        [ 9.1745e-02],\n",
              "        [-2.6974e-01],\n",
              "        [-2.1966e-01]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVQ-KOL1LXNQ",
        "outputId": "f0fdc308-b2dc-470f-9219-3cc751cf9561"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.2999, -0.1944, -0.4471, -0.0693,  0.0897]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY47zxPALyQM",
        "outputId": "f99765bd-1728-4758-c186-76916d378dfe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.1977], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5)\n",
        "linear_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVGgQcSyL0ok",
        "outputId": "0eeec4a3-b55e-4488-da94-4f8dc050cc5e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5189], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(10, 5)\n",
        "linear_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxLpnpAANGPh",
        "outputId": "0a422ca5-f7c3-483b-a076-45b059349073"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189],\n",
              "        [-0.5189]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized = torch.tensor(data_normalized).unsqueeze(1)\n",
        "target_normalized = torch.tensor(target_normalized).unsqueeze(1)\n",
        "\n",
        "\n",
        "data_normalized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBxmuKSeNQ9n",
        "outputId": "7209f7fb-bf7b-45bc-d1ea-0e37f7e5c64c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([545, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_normalized.shape\n",
        "\n",
        "train_price = torch.tensor(train_price).unsqueeze(1)\n",
        "\n",
        "eval_price = torch.tensor(eval_price).unsqueeze(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOS8TuyyPJwI",
        "outputId": "90d79805-700f-49a3-d371-c46fb4a1ce08"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86iR8w4SjV55",
        "outputId": "08567fd7-645b-499b-f409-632fc2b46ac3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([109, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(5, 1)\n",
        "optimizer = optim.SGD(\n",
        "  linear_model.parameters(),\n",
        "  lr=1e-2)"
      ],
      "metadata": {
        "id": "AqYHvQFJP2MM"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1z-TV-kQDTu",
        "outputId": "29f1c2d5-7ddf-41a6-f947-a73bd77ed33d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f7380782250>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(linear_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_C5F8lQQGrp",
        "outputId": "84f5ad92-e8e6-492a-eeb4-a5912da130e2"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.3737, 0.0647, 0.2960, 0.2515, 0.1902]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0072], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_data, train_price,\n",
        "                  eval_data, eval_price):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    price_train = model(train_data)\n",
        "    train_loss = loss_fn(price_train, train_price)\n",
        "\n",
        "    price_eval = model(eval_data)\n",
        "    eval_loss = loss_fn(price_eval, eval_price)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch == 1 or epoch % 50 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "            f\" Validation loss {eval_loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "abIfh04sQLXv"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(5, 1)\n",
        "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 3000,\n",
        "  optimizer = optimizer,\n",
        "  model = linear_model,\n",
        "  loss_fn = nn.MSELoss(),\n",
        "  train_data = train_data,\n",
        "  train_price = train_price,\n",
        "  eval_data = eval_data,\n",
        "  eval_price = eval_price)\n",
        "\n",
        "print()\n",
        "print(linear_model.weight)\n",
        "print(linear_model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0u1VtgwSsEL",
        "outputId": "2ffd2f97-ab51-48ca-8217-689307b49edb"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 1.5713, Validation loss 1.4073\n",
            "Epoch 50, Training loss 0.4745, Validation loss 0.4925\n",
            "Epoch 100, Training loss 0.4405, Validation loss 0.4543\n",
            "Epoch 150, Training loss 0.4373, Validation loss 0.4482\n",
            "Epoch 200, Training loss 0.4367, Validation loss 0.4462\n",
            "Epoch 250, Training loss 0.4365, Validation loss 0.4453\n",
            "Epoch 300, Training loss 0.4364, Validation loss 0.4449\n",
            "Epoch 350, Training loss 0.4364, Validation loss 0.4447\n",
            "Epoch 400, Training loss 0.4364, Validation loss 0.4446\n",
            "Epoch 450, Training loss 0.4364, Validation loss 0.4445\n",
            "Epoch 500, Training loss 0.4364, Validation loss 0.4445\n",
            "Epoch 550, Training loss 0.4364, Validation loss 0.4445\n",
            "Epoch 600, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 650, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 700, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 750, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 800, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 850, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 900, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 950, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1000, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1050, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1100, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1150, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1200, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1250, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1300, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1350, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1400, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1450, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1500, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1550, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1600, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1650, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1700, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1750, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1800, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1850, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1900, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 1950, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2000, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2050, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2100, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2150, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2200, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2250, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2300, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2350, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2400, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2450, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2500, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2550, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2600, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2650, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2700, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2750, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2800, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2850, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2900, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 2950, Training loss 0.4364, Validation loss 0.4444\n",
            "Epoch 3000, Training loss 0.4364, Validation loss 0.4444\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[0.3737, 0.0647, 0.2960, 0.2515, 0.1902]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0072], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = nn.Sequential(\n",
        "            nn.Linear(1, 13),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(13, 1))\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4BxYSxgS-tC",
        "outputId": "54dd74af-62a2-4ca7-9c1c-8a704285a25f"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[param.shape for param in seq_model.parameters()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLwJI8W1Uv3L",
        "outputId": "41c69e64-9862-4619-a8af-19cf136271f0"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])]"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgdUSpBoU5is",
        "outputId": "ff69618e-aa37-4d49-8405-b810cf2e9262"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([13, 1])\n",
            "0.bias torch.Size([13])\n",
            "2.weight torch.Size([1, 13])\n",
            "2.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "seq_model = nn.Sequential(OrderedDict([\n",
        "  ('hidden_linear', nn.Linear(5, 8)),\n",
        "  ('hidden_activation', nn.Tanh()),\n",
        "  ('output_linear', nn.Linear(8, 5)),\n",
        "]))\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "degPACFQVIDC",
        "outputId": "f682f97a-a33f-4108-bc48-1d86f136c0fb"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (output_linear): Linear(in_features=8, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_ky7hluVeRr",
        "outputId": "0cc948ee-8297-475c-dca6-667f9cffdb7a"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_linear.weight torch.Size([8, 5])\n",
            "hidden_linear.bias torch.Size([8])\n",
            "output_linear.weight torch.Size([5, 8])\n",
            "output_linear.bias torch.Size([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model.output_linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0qYIOZnVirC",
        "outputId": "24f0762b-e0f3-470c-87ab-5d6a2173ed28"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 0.3377, -0.0539, -0.1557, -0.1014, -0.1906], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##train_price_fixed = train_price.clone().detach()\n",
        "#train_price_fixed.shape\n",
        "train_price = torch.tensor(train_price).squeeze(1)\n",
        "train_price = torch.tensor(train_price).unsqueeze(1)\n",
        "train_price.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNM0IVq2de1F",
        "outputId": "44a06aa9-fc8f-410d-d3c4-42e5f7325383"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([436, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_price = torch.tensor(eval_price).squeeze(1)\n",
        "eval_price = torch.tensor(eval_price).unsqueeze(1)\n",
        "eval_price.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxTTsYUtd8Zs",
        "outputId": "4e857351-f874-4d53-92bf-ee071114dc97"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([109, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-5)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 200,\n",
        "  optimizer = optimizer,\n",
        "  model = seq_model,\n",
        "  loss_fn = nn.MSELoss(),\n",
        "  train_data = train_data,\n",
        "  train_price = train_price,\n",
        "  eval_data = eval_data,\n",
        "  eval_price = eval_price)\n",
        "\n",
        "  #return F.mse_loss(input, target, reduction=self.reduction)\n",
        "print('output', seq_model(eval_data))\n",
        "print('answer', eval_price)\n",
        "print('hidden', seq_model.hidden_linear.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7CqRxRjVoB1",
        "outputId": "5301ef44-41e2-45c3-d7d4-90da6c50710c"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 1.2016, Validation loss 1.0584\n",
            "Epoch 50, Training loss 1.2013, Validation loss 1.0581\n",
            "Epoch 100, Training loss 1.2011, Validation loss 1.0579\n",
            "Epoch 150, Training loss 1.2008, Validation loss 1.0577\n",
            "Epoch 200, Training loss 1.2005, Validation loss 1.0574\n",
            "output tensor([[ 0.5214,  0.0668, -0.0480,  0.1604, -0.0431],\n",
            "        [ 0.5949, -0.4415, -0.1387, -0.1567, -0.0455],\n",
            "        [ 0.5089, -0.2280, -0.4883, -0.3952, -0.3583],\n",
            "        [ 0.3482, -0.1252,  0.1048, -0.4208, -0.2160],\n",
            "        [ 0.1989, -0.0410, -0.1121, -0.4397, -0.2047],\n",
            "        [ 0.3689,  0.1087,  0.0709, -0.3243, -0.3086],\n",
            "        [ 0.3471, -0.1756,  0.1086, -0.4344, -0.2023],\n",
            "        [ 0.1171,  0.0095, -0.4501, -0.6303, -0.4646],\n",
            "        [ 0.1907,  0.1003, -0.1300, -0.3107, -0.2852],\n",
            "        [ 0.6030, -0.2323,  0.2769, -0.0482,  0.0310],\n",
            "        [ 0.4135, -0.3936, -0.3426, -0.1660,  0.0144],\n",
            "        [ 0.2431, -0.1190, -0.6081, -0.4879, -0.3688],\n",
            "        [-0.0120,  0.3412, -0.2849, -0.3462, -0.3681],\n",
            "        [ 0.3175, -0.0304, -0.2824, -0.1628, -0.1937],\n",
            "        [ 0.3217,  0.0363, -0.2925, -0.1451, -0.2230],\n",
            "        [ 0.3886,  0.1375,  0.4030, -0.0717, -0.1170],\n",
            "        [ 0.3169, -0.0400, -0.2809, -0.1656, -0.1894],\n",
            "        [ 0.3120, -0.1271, -0.2682, -0.1924, -0.1500],\n",
            "        [ 0.4560, -0.2274,  0.0776, -0.1039,  0.0749],\n",
            "        [ 0.6521, -0.1309,  0.1377,  0.2022,  0.0441],\n",
            "        [ 0.6529, -0.1289,  0.1370,  0.2029,  0.0429],\n",
            "        [ 0.0415, -0.0924,  0.0935, -0.6323, -0.2808],\n",
            "        [ 0.4608, -0.0195,  0.0175,  0.1457,  0.0120],\n",
            "        [ 0.0538,  0.1120, -0.3192, -0.7174, -0.5149],\n",
            "        [ 0.0170,  0.0239, -0.3676, -0.2805, -0.1912],\n",
            "        [ 0.5981, -0.4105, -0.1430, -0.1488, -0.0588],\n",
            "        [-0.0586, -0.0208, -0.2051, -0.0624,  0.0606],\n",
            "        [-0.0790,  0.2134, -0.4996, -0.6075, -0.5091],\n",
            "        [ 0.5362,  0.0241,  0.2884,  0.0717, -0.0602],\n",
            "        [ 0.6126, -0.1685, -0.1671, -0.0697, -0.1684],\n",
            "        [ 0.4181, -0.2840,  0.1420, -0.1178,  0.0054],\n",
            "        [ 0.1829, -0.1098, -0.1084, -0.3769, -0.1921],\n",
            "        [ 0.5052, -0.0438,  0.3172,  0.0507, -0.0197],\n",
            "        [ 0.6010, -0.3813, -0.1469, -0.1406, -0.0717],\n",
            "        [ 0.5365,  0.0247,  0.2881,  0.0718, -0.0607],\n",
            "        [ 0.6529, -0.1289,  0.1370,  0.2029,  0.0429],\n",
            "        [ 0.0546,  0.2479, -0.2352, -0.7127, -0.5381],\n",
            "        [ 0.4037, -0.1693,  0.0816,  0.1075,  0.0874],\n",
            "        [-0.1503,  0.3052, -0.3281, -0.6871, -0.5695],\n",
            "        [ 0.2576,  0.0850,  0.1392, -0.4844, -0.2614],\n",
            "        [ 0.4863,  0.0192, -0.0099,  0.1534, -0.0121],\n",
            "        [ 0.0754,  0.2239, -0.4340, -0.2297, -0.2821],\n",
            "        [ 0.5433, -0.0562,  0.5615,  0.1965,  0.1471],\n",
            "        [ 0.3163, -0.0505, -0.2793, -0.1687, -0.1847],\n",
            "        [ 0.6432, -0.2426, -0.2545,  0.1167,  0.1788],\n",
            "        [ 0.1904, -0.1174, -0.0953, -0.4494, -0.1805],\n",
            "        [ 0.3177, -0.1441, -0.2440, -0.2959, -0.1336],\n",
            "        [ 0.3215,  0.0336, -0.2921, -0.1458, -0.2218],\n",
            "        [ 0.3173, -0.0345, -0.2817, -0.1640, -0.1919],\n",
            "        [ 0.2107,  0.1042, -0.1373, -0.3896, -0.2670],\n",
            "        [ 0.1348, -0.0539, -0.0190, -0.5451, -0.2283],\n",
            "        [ 0.4810,  0.0117, -0.0043,  0.1521, -0.0073],\n",
            "        [ 0.6489, -0.2057,  0.0107,  0.3692,  0.3463],\n",
            "        [ 0.3169,  0.0311,  0.2129, -0.1034, -0.0305],\n",
            "        [ 0.6240, -0.2274,  0.1599,  0.1703,  0.0917],\n",
            "        [ 0.5205, -0.0063,  0.3031,  0.0621, -0.0410],\n",
            "        [ 0.3210,  0.0249, -0.2908, -0.1479, -0.2181],\n",
            "        [ 0.1995,  0.1679, -0.1432, -0.2891, -0.3185],\n",
            "        [ 0.1839,  0.0243, -0.1184, -0.3358, -0.2491],\n",
            "        [ 0.2655, -0.4176, -0.1643, -0.2726, -0.0438],\n",
            "        [-0.0586, -0.0208, -0.2051, -0.0624,  0.0606],\n",
            "        [ 0.6487, -0.1392,  0.1404,  0.1995,  0.0487],\n",
            "        [ 0.6521, -0.1309,  0.1377,  0.2022,  0.0441],\n",
            "        [ 0.6529, -0.1289,  0.1370,  0.2029,  0.0429],\n",
            "        [ 0.6440, -0.1518,  0.1444,  0.1953,  0.0554],\n",
            "        [-0.0586, -0.0208, -0.2051, -0.0624,  0.0606],\n",
            "        [ 0.3470, -0.2477,  0.1126, -0.4476, -0.1873],\n",
            "        [ 0.1168,  0.0048, -0.4497, -0.6320, -0.4624],\n",
            "        [ 0.3420, -0.0420,  0.4554, -0.1214, -0.0401],\n",
            "        [ 0.6177, -0.2925,  0.1625,  0.1493,  0.1169],\n",
            "        [ 0.5848, -0.5399, -0.1252, -0.1743, -0.0074],\n",
            "        [ 0.3207,  0.0203, -0.2901, -0.1490, -0.2161],\n",
            "        [ 0.6113, -0.2381, -0.1627, -0.0937, -0.1371],\n",
            "        [-0.1358,  0.0368, -0.4521, -0.4315, -0.1613],\n",
            "        [ 0.6095, -0.0796, -0.1685, -0.0408, -0.2061],\n",
            "        [ 0.6075, -0.4899, -0.2127, -0.0968,  0.0356],\n",
            "        [ 0.2223,  0.0500,  0.4995, -0.2458, -0.0799],\n",
            "        [ 0.2513, -0.2285, -0.1422,  0.0351,  0.1424],\n",
            "        [ 0.0361,  0.1022, -0.3906, -0.2555, -0.2281],\n",
            "        [ 0.3683,  0.0988,  0.4246, -0.0846, -0.0942],\n",
            "        [-0.2410,  0.2880,  0.0058, -0.2718, -0.0734],\n",
            "        [ 0.1070,  0.2804, -0.0130, -0.4023, -0.3814],\n",
            "        [ 0.3470, -0.2491,  0.1126, -0.4478, -0.1871],\n",
            "        [ 0.5294, -0.0926, -0.0871,  0.2017,  0.0973],\n",
            "        [ 0.3057,  0.1104,  0.2159, -0.0829, -0.0567],\n",
            "        [ 0.0024, -0.1119, -0.2596, -0.8050, -0.4143],\n",
            "        [ 0.0994,  0.2528, -0.0044, -0.4142, -0.3672],\n",
            "        [ 0.0548,  0.1910, -0.3226, -0.6786, -0.5466],\n",
            "        [ 0.3469, -0.2350,  0.1120, -0.4459, -0.1895],\n",
            "        [ 0.5250, -0.1753, -0.0797,  0.1717,  0.1310],\n",
            "        [ 0.3352,  0.0195, -0.2709, -0.2390, -0.2165],\n",
            "        [ 0.4830, -0.1775, -0.4195, -0.1109, -0.0954],\n",
            "        [ 0.3209,  0.0226, -0.2904, -0.1485, -0.2171],\n",
            "        [ 0.3058,  0.1088,  0.2159, -0.0834, -0.0561],\n",
            "        [ 0.4858, -0.1584, -0.4227, -0.1038, -0.1050],\n",
            "        [ 0.0779,  0.2313, -0.4367, -0.2290, -0.2850],\n",
            "        [ 0.5315,  0.0372,  0.5742,  0.2108,  0.1256],\n",
            "        [ 0.1936, -0.1768, -0.0743, -0.0886,  0.0824],\n",
            "        [ 0.6064, -0.3197, -0.1546, -0.1213, -0.0996],\n",
            "        [ 0.4664, -0.5268,  0.0219, -0.3122, -0.0831],\n",
            "        [ 0.3119, -0.1279, -0.2680, -0.1927, -0.1496],\n",
            "        [ 0.4513, -0.0357,  0.0278,  0.1420,  0.0217],\n",
            "        [ 0.1958,  0.1409, -0.1377, -0.2976, -0.3052],\n",
            "        [ 0.5782, -0.6299, -0.1154, -0.1759,  0.0194],\n",
            "        [ 0.0036, -0.0747, -0.3478, -0.3158, -0.1468],\n",
            "        [ 0.2271,  0.0214, -0.5999, -0.4518, -0.4223],\n",
            "        [ 0.0308, -0.0891, -0.6792, -0.5502, -0.3453],\n",
            "        [ 0.3477, -0.1444,  0.1063, -0.4264, -0.2105],\n",
            "        [ 0.3557, -0.0030,  0.0906, -0.3757, -0.2592]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "answer tensor([[-1.1263e+00],\n",
            "        [ 3.5193e-01],\n",
            "        [-4.1527e-01],\n",
            "        [ 5.2034e-01],\n",
            "        [ 5.2034e-01],\n",
            "        [-6.0613e-01],\n",
            "        [ 5.5403e-01],\n",
            "        [ 5.2034e-01],\n",
            "        [-1.0889e+00],\n",
            "        [ 4.0807e-01],\n",
            "        [ 2.5837e-01],\n",
            "        [-7.7080e-01],\n",
            "        [-3.0299e-01],\n",
            "        [-8.8307e-01],\n",
            "        [ 7.1251e-02],\n",
            "        [-7.5208e-01],\n",
            "        [-1.9072e-01],\n",
            "        [ 8.9459e-01],\n",
            "        [ 2.6273e+00],\n",
            "        [-1.0141e+00],\n",
            "        [-5.8368e-01],\n",
            "        [-6.7724e-01],\n",
            "        [-1.3458e-01],\n",
            "        [-1.5330e-01],\n",
            "        [ 5.5777e-01],\n",
            "        [ 6.3262e-01],\n",
            "        [ 1.9762e+00],\n",
            "        [ 7.1682e-01],\n",
            "        [-1.2386e+00],\n",
            "        [-1.1587e-01],\n",
            "        [ 2.0360e+00],\n",
            "        [-4.1527e-01],\n",
            "        [-7.7080e-01],\n",
            "        [ 2.5463e-01],\n",
            "        [-1.5567e+00],\n",
            "        [-5.2754e-01],\n",
            "        [-9.3921e-01],\n",
            "        [ 1.6481e-01],\n",
            "        [-3.7784e-01],\n",
            "        [-3.9655e-01],\n",
            "        [-7.8447e-02],\n",
            "        [-6.0239e-01],\n",
            "        [ 2.7708e-01],\n",
            "        [ 7.1251e-02],\n",
            "        [-3.0299e-01],\n",
            "        [ 2.0173e+00],\n",
            "        [ 1.8863e+00],\n",
            "        [-6.7724e-01],\n",
            "        [-2.0943e-01],\n",
            "        [ 2.3916e+00],\n",
            "        [ 3.9821e+00],\n",
            "        [-6.0239e-01],\n",
            "        [-1.1263e+00],\n",
            "        [ 2.2044e+00],\n",
            "        [-9.0178e-01],\n",
            "        [-1.1263e+00],\n",
            "        [-9.7663e-01],\n",
            "        [-6.7724e-01],\n",
            "        [-1.9446e-01],\n",
            "        [-4.1022e-02],\n",
            "        [ 9.6944e-01],\n",
            "        [-1.7201e-01],\n",
            "        [-5.8368e-01],\n",
            "        [-1.1638e+00],\n",
            "        [-8.0822e-01],\n",
            "        [ 5.3906e-01],\n",
            "        [ 3.8936e-01],\n",
            "        [ 4.4549e-01],\n",
            "        [-5.2754e-01],\n",
            "        [ 7.1251e-02],\n",
            "        [-1.5330e-01],\n",
            "        [-1.2386e+00],\n",
            "        [-3.7784e-01],\n",
            "        [ 1.4934e+00],\n",
            "        [-1.1263e+00],\n",
            "        [ 4.4549e-01],\n",
            "        [-7.3403e-03],\n",
            "        [ 1.0069e+00],\n",
            "        [ 3.3827e-02],\n",
            "        [-4.5269e-01],\n",
            "        [ 1.3811e+00],\n",
            "        [-9.3921e-01],\n",
            "        [ 6.7004e-01],\n",
            "        [ 1.8352e-01],\n",
            "        [-3.9655e-01],\n",
            "        [ 1.4610e-01],\n",
            "        [-4.1022e-02],\n",
            "        [-7.5208e-01],\n",
            "        [ 2.9580e-01],\n",
            "        [ 1.0817e+00],\n",
            "        [ 3.8936e-01],\n",
            "        [ 1.4462e-04],\n",
            "        [-6.0239e-01],\n",
            "        [ 4.0807e-01],\n",
            "        [-4.7140e-01],\n",
            "        [-6.9595e-01],\n",
            "        [-4.9011e-01],\n",
            "        [ 1.7516e+00],\n",
            "        [-1.3546e+00],\n",
            "        [ 2.5837e-01],\n",
            "        [-7.8447e-02],\n",
            "        [-4.7140e-01],\n",
            "        [-9.7663e-01],\n",
            "        [-1.3458e-01],\n",
            "        [ 7.2618e-01],\n",
            "        [-1.4257e+00],\n",
            "        [ 8.0103e-01],\n",
            "        [ 7.0746e-01],\n",
            "        [-1.9446e-01]])\n",
            "hidden tensor([[ 0.2661,  0.2007,  0.2169,  0.2286,  0.1966],\n",
            "        [ 0.0923,  0.0852,  0.0892,  0.0995,  0.0718],\n",
            "        [ 0.0586,  0.0389,  0.0401,  0.0542,  0.0675],\n",
            "        [ 0.0766,  0.0541,  0.0516,  0.0589,  0.0544],\n",
            "        [-0.0597, -0.0499, -0.0519, -0.0548, -0.0293],\n",
            "        [ 0.0166, -0.0054,  0.0062,  0.0080,  0.0229],\n",
            "        [-0.0535, -0.0328, -0.0399, -0.0517, -0.0518],\n",
            "        [-0.0130, -0.0305, -0.0097, -0.0184, -0.0050]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([436, 1])) that is different to the input size (torch.Size([436, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([109, 1])) that is different to the input size (torch.Size([109, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IR5y7ZKmVq_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}