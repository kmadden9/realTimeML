{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2-Q1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNT44rQNxLHQ6T4d3FrIkSZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmadden9/realTimeML/blob/main/HW/HW2/HW2_Q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE2R-tCbj2F1",
        "outputId": "4f4cbae8-c169-4e9f-a24d-b8c88425cdff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Kevin Madden \n",
        "#Due Date: 2/28/2022\n",
        "#Professor: Dr. Hamed Tabkhi, PH.D.\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "#checking if I have GPU connected\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.A\n",
        "import csv\n",
        "housing_path = \"https://raw.githubusercontent.com/kmadden9/realTimeML/main/Housing_fixed.csv\"\n",
        "house_numpy = np.loadtxt(housing_path, dtype=np.float32, delimiter=\",\", skiprows=1)\n",
        "house_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSTHwS9ukTLS",
        "outputId": "48f38249-3031-46f0-9c2c-b99b38966393"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.330e+07, 7.420e+03, 4.000e+00, 2.000e+00, 3.000e+00, 2.000e+00],\n",
              "       [1.225e+07, 8.960e+03, 4.000e+00, 4.000e+00, 4.000e+00, 3.000e+00],\n",
              "       [1.225e+07, 9.960e+03, 3.000e+00, 2.000e+00, 2.000e+00, 2.000e+00],\n",
              "       ...,\n",
              "       [1.750e+06, 3.620e+03, 2.000e+00, 1.000e+00, 1.000e+00, 0.000e+00],\n",
              "       [1.750e+06, 2.910e+03, 3.000e+00, 1.000e+00, 1.000e+00, 0.000e+00],\n",
              "       [1.750e+06, 3.850e+03, 3.000e+00, 1.000e+00, 2.000e+00, 0.000e+00]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col_list = next(csv.reader(open('/content/raw.githubusercontent.com/kmadden9/realTimeML/main/Housing_fixed.csv'), delimiter=','))\n",
        "house_numpy.shape, col_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BCDocIkkdd5",
        "outputId": "5f96f6c3-cc76-47ea-e342-8b3cdfbbe7f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((545, 6), ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "house = torch.from_numpy(house_numpy)\n",
        "house.shape, house.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VAuEqL4kdqy",
        "outputId": "8cc859fe-2c7e-4141-9bc0-dd0670c77415"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([545, 6]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = house[:, 1:]\n",
        "target = house[:, 0]\n",
        "data_mean = torch.mean(data, dim=0)\n",
        "data_var = torch.var(data, dim=0)\n",
        "target_mean = torch.mean(target, dim=0)\n",
        "target_var = torch.var(target, dim=0)\n",
        "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
        "target_normalized = (target - target_mean) / torch.sqrt(target_var)\n",
        "\n",
        "area = torch.stack(tuple(data_normalized[:,0]))\n",
        "bedrooms = torch.stack(tuple(data_normalized[:,1]))\n",
        "bathrooms = torch.stack(tuple(data_normalized[:,2]))\n",
        "stories = torch.stack(tuple(data_normalized[:,3]))\n",
        "parking = torch.stack(tuple(data_normalized[:,4]))"
      ],
      "metadata": {
        "id": "-DHwTV83kd1Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtljWIAAkd-I",
        "outputId": "1810fb6b-f06c-4aa5-d307-8813cb6af597"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13300000., 12250000., 12250000., 12215000., 11410000., 10850000.,\n",
              "        10150000., 10150000.,  9870000.,  9800000.,  9800000.,  9681000.,\n",
              "         9310000.,  9240000.,  9240000.,  9100000.,  9100000.,  8960000.,\n",
              "         8890000.,  8855000.,  8750000.,  8680000.,  8645000.,  8645000.,\n",
              "         8575000.,  8540000.,  8463000.,  8400000.,  8400000.,  8400000.,\n",
              "         8400000.,  8400000.,  8295000.,  8190000.,  8120000.,  8080940.,\n",
              "         8043000.,  7980000.,  7962500.,  7910000.,  7875000.,  7840000.,\n",
              "         7700000.,  7700000.,  7560000.,  7560000.,  7525000.,  7490000.,\n",
              "         7455000.,  7420000.,  7420000.,  7420000.,  7350000.,  7350000.,\n",
              "         7350000.,  7350000.,  7343000.,  7245000.,  7210000.,  7210000.,\n",
              "         7140000.,  7070000.,  7070000.,  7035000.,  7000000.,  6930000.,\n",
              "         6930000.,  6895000.,  6860000.,  6790000.,  6790000.,  6755000.,\n",
              "         6720000.,  6685000.,  6650000.,  6650000.,  6650000.,  6650000.,\n",
              "         6650000.,  6650000.,  6629000.,  6615000.,  6615000.,  6580000.,\n",
              "         6510000.,  6510000.,  6510000.,  6475000.,  6475000.,  6440000.,\n",
              "         6440000.,  6419000.,  6405000.,  6300000.,  6300000.,  6300000.,\n",
              "         6300000.,  6300000.,  6293000.,  6265000.,  6230000.,  6230000.,\n",
              "         6195000.,  6195000.,  6195000.,  6160000.,  6160000.,  6125000.,\n",
              "         6107500.,  6090000.,  6090000.,  6090000.,  6083000.,  6083000.,\n",
              "         6020000.,  6020000.,  6020000.,  5950000.,  5950000.,  5950000.,\n",
              "         5950000.,  5950000.,  5950000.,  5950000.,  5950000.,  5943000.,\n",
              "         5880000.,  5880000.,  5873000.,  5873000.,  5866000.,  5810000.,\n",
              "         5810000.,  5810000.,  5803000.,  5775000.,  5740000.,  5740000.,\n",
              "         5740000.,  5740000.,  5740000.,  5652500.,  5600000.,  5600000.,\n",
              "         5600000.,  5600000.,  5600000.,  5600000.,  5600000.,  5600000.,\n",
              "         5600000.,  5565000.,  5565000.,  5530000.,  5530000.,  5530000.,\n",
              "         5523000.,  5495000.,  5495000.,  5460000.,  5460000.,  5460000.,\n",
              "         5460000.,  5425000.,  5390000.,  5383000.,  5320000.,  5285000.,\n",
              "         5250000.,  5250000.,  5250000.,  5250000.,  5250000.,  5250000.,\n",
              "         5250000.,  5250000.,  5250000.,  5243000.,  5229000.,  5215000.,\n",
              "         5215000.,  5215000.,  5145000.,  5145000.,  5110000.,  5110000.,\n",
              "         5110000.,  5110000.,  5075000.,  5040000.,  5040000.,  5040000.,\n",
              "         5040000.,  5033000.,  5005000.,  4970000.,  4970000.,  4956000.,\n",
              "         4935000.,  4907000.,  4900000.,  4900000.,  4900000.,  4900000.,\n",
              "         4900000.,  4900000.,  4900000.,  4900000.,  4900000.,  4900000.,\n",
              "         4900000.,  4900000.,  4893000.,  4893000.,  4865000.,  4830000.,\n",
              "         4830000.,  4830000.,  4830000.,  4795000.,  4795000.,  4767000.,\n",
              "         4760000.,  4760000.,  4760000.,  4753000.,  4690000.,  4690000.,\n",
              "         4690000.,  4690000.,  4690000.,  4690000.,  4655000.,  4620000.,\n",
              "         4620000.,  4620000.,  4620000.,  4620000.,  4613000.,  4585000.,\n",
              "         4585000.,  4550000.,  4550000.,  4550000.,  4550000.,  4550000.,\n",
              "         4550000.,  4550000.,  4543000.,  4543000.,  4515000.,  4515000.,\n",
              "         4515000.,  4515000.,  4480000.,  4480000.,  4480000.,  4480000.,\n",
              "         4480000.,  4473000.,  4473000.,  4473000.,  4445000.,  4410000.,\n",
              "         4410000.,  4403000.,  4403000.,  4403000.,  4382000.,  4375000.,\n",
              "         4340000.,  4340000.,  4340000.,  4340000.,  4340000.,  4319000.,\n",
              "         4305000.,  4305000.,  4277000.,  4270000.,  4270000.,  4270000.,\n",
              "         4270000.,  4270000.,  4270000.,  4235000.,  4235000.,  4200000.,\n",
              "         4200000.,  4200000.,  4200000.,  4200000.,  4200000.,  4200000.,\n",
              "         4200000.,  4200000.,  4200000.,  4200000.,  4200000.,  4200000.,\n",
              "         4200000.,  4200000.,  4200000.,  4200000.,  4193000.,  4193000.,\n",
              "         4165000.,  4165000.,  4165000.,  4130000.,  4130000.,  4123000.,\n",
              "         4098500.,  4095000.,  4095000.,  4095000.,  4060000.,  4060000.,\n",
              "         4060000.,  4060000.,  4060000.,  4025000.,  4025000.,  4025000.,\n",
              "         4007500.,  4007500.,  3990000.,  3990000.,  3990000.,  3990000.,\n",
              "         3990000.,  3920000.,  3920000.,  3920000.,  3920000.,  3920000.,\n",
              "         3920000.,  3920000.,  3885000.,  3885000.,  3850000.,  3850000.,\n",
              "         3850000.,  3850000.,  3850000.,  3850000.,  3850000.,  3836000.,\n",
              "         3815000.,  3780000.,  3780000.,  3780000.,  3780000.,  3780000.,\n",
              "         3780000.,  3773000.,  3773000.,  3773000.,  3745000.,  3710000.,\n",
              "         3710000.,  3710000.,  3710000.,  3710000.,  3703000.,  3703000.,\n",
              "         3675000.,  3675000.,  3675000.,  3675000.,  3640000.,  3640000.,\n",
              "         3640000.,  3640000.,  3640000.,  3640000.,  3640000.,  3640000.,\n",
              "         3640000.,  3633000.,  3605000.,  3605000.,  3570000.,  3570000.,\n",
              "         3570000.,  3570000.,  3535000.,  3500000.,  3500000.,  3500000.,\n",
              "         3500000.,  3500000.,  3500000.,  3500000.,  3500000.,  3500000.,\n",
              "         3500000.,  3500000.,  3500000.,  3500000.,  3500000.,  3500000.,\n",
              "         3500000.,  3500000.,  3493000.,  3465000.,  3465000.,  3465000.,\n",
              "         3430000.,  3430000.,  3430000.,  3430000.,  3430000.,  3430000.,\n",
              "         3423000.,  3395000.,  3395000.,  3395000.,  3360000.,  3360000.,\n",
              "         3360000.,  3360000.,  3360000.,  3360000.,  3360000.,  3360000.,\n",
              "         3353000.,  3332000.,  3325000.,  3325000.,  3290000.,  3290000.,\n",
              "         3290000.,  3290000.,  3290000.,  3290000.,  3290000.,  3290000.,\n",
              "         3255000.,  3255000.,  3234000.,  3220000.,  3220000.,  3220000.,\n",
              "         3220000.,  3150000.,  3150000.,  3150000.,  3150000.,  3150000.,\n",
              "         3150000.,  3150000.,  3150000.,  3150000.,  3143000.,  3129000.,\n",
              "         3118850.,  3115000.,  3115000.,  3115000.,  3087000.,  3080000.,\n",
              "         3080000.,  3080000.,  3080000.,  3045000.,  3010000.,  3010000.,\n",
              "         3010000.,  3010000.,  3010000.,  3010000.,  3010000.,  3003000.,\n",
              "         2975000.,  2961000.,  2940000.,  2940000.,  2940000.,  2940000.,\n",
              "         2940000.,  2940000.,  2940000.,  2940000.,  2870000.,  2870000.,\n",
              "         2870000.,  2870000.,  2852500.,  2835000.,  2835000.,  2835000.,\n",
              "         2800000.,  2800000.,  2730000.,  2730000.,  2695000.,  2660000.,\n",
              "         2660000.,  2660000.,  2660000.,  2660000.,  2660000.,  2660000.,\n",
              "         2653000.,  2653000.,  2604000.,  2590000.,  2590000.,  2590000.,\n",
              "         2520000.,  2520000.,  2520000.,  2485000.,  2485000.,  2450000.,\n",
              "         2450000.,  2450000.,  2450000.,  2450000.,  2450000.,  2408000.,\n",
              "         2380000.,  2380000.,  2380000.,  2345000.,  2310000.,  2275000.,\n",
              "         2275000.,  2275000.,  2240000.,  2233000.,  2135000.,  2100000.,\n",
              "         2100000.,  2100000.,  1960000.,  1890000.,  1890000.,  1855000.,\n",
              "         1820000.,  1767150.,  1750000.,  1750000.,  1750000.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = target.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "train_indices, val_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI0aAnxFBgZo",
        "outputId": "a414a2e3-b397-43c0-c225-1f1dc752e3c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([252, 341, 177,   0,  47, 534,  42, 240, 543, 111, 383,  64, 136, 303,\n",
              "         195, 367, 293, 473,   1,  27, 377, 538, 261, 126, 436,  54, 110, 127,\n",
              "         374, 544, 258, 410, 125, 226, 267, 145,   3, 257,  92, 196, 477, 420,\n",
              "         418, 109, 133, 247, 385,  77, 192, 130, 312, 238, 260, 149, 443,  52,\n",
              "         516, 457, 248, 510, 500, 508, 347,  83,  67, 212, 102, 202, 284, 467,\n",
              "         480,  37,  17, 280,  13, 206,  48, 527, 483, 182, 499, 314,  58, 160,\n",
              "         237,  78, 173, 450, 461, 236, 287, 318, 201, 432, 504, 517, 540, 442,\n",
              "          99, 532, 362, 403, 423, 357, 186, 379, 366, 404, 189, 138, 498, 274,\n",
              "         386, 276, 279, 235,  44, 108,  60, 115, 264,  40,  80, 140, 511,  16,\n",
              "         488, 424,  94, 334, 211, 225, 430, 224, 233, 271, 179, 123, 425, 162,\n",
              "         281, 205, 208, 460, 291, 354, 301, 396, 302, 166, 382, 327, 117, 199,\n",
              "         335,  79, 384, 105, 227, 419, 531, 494, 241, 400, 157, 143, 402, 167,\n",
              "         373, 537, 255, 155, 132, 496, 118,  19, 539, 449, 119, 144, 285, 121,\n",
              "         395, 458, 218, 363, 406,  74, 345, 161,  66, 369, 459,  33, 330, 361,\n",
              "         339,  12, 200, 272, 376, 512,  73, 328, 518, 316, 533, 360, 308, 352,\n",
              "         371, 256, 193, 478, 300, 307, 207, 536, 428, 106, 380, 191, 454,  69,\n",
              "          81, 456, 185, 445,  95,  25,  26, 214, 137, 368, 503,  70, 407, 228,\n",
              "         530, 250, 142,  20, 165, 465, 151, 289, 348, 265,  43, 447, 422, 482,\n",
              "         209, 541, 331, 322, 178, 439, 306, 175, 231,  10,  72, 103, 486, 444,\n",
              "         295, 398, 412, 101,  38, 336, 342,   4, 481, 472, 370,  91, 313,  23,\n",
              "         351, 309, 381, 169, 485, 519, 230, 268,   5, 141, 514, 440, 502,   2,\n",
              "         292, 487, 298, 365,  75, 353, 217,  41,  22, 181, 489, 378, 455, 135,\n",
              "         475, 349, 426, 154,  15,  61, 464, 223, 501, 124, 275, 332, 172, 520,\n",
              "         245, 180, 387,  34, 452,   8, 491, 414,  21, 204, 338, 397, 254, 346,\n",
              "         513,  88, 393, 451, 114, 441, 411, 148, 277, 542,  14, 399, 416, 466,\n",
              "         415, 524, 251, 304, 474,   7,  87, 278, 283, 469,  32,  51, 325, 435,\n",
              "         535, 413, 463,  11, 358, 187, 344, 190, 163,  46, 429, 305,  30, 359,\n",
              "         246, 266, 116, 263,  24, 131, 317, 159, 286, 239, 375, 319,  98, 156,\n",
              "          84, 427,  39, 210, 329, 505, 446,  93, 320, 529, 333,  85, 437, 168,\n",
              "         326, 390,  49, 220, 528, 521, 215, 490, 324, 372, 128, 476, 104, 273,\n",
              "         433, 262, 270, 183, 522,  59, 523, 350,   6,  29, 290, 392, 170, 112,\n",
              "         198,  96]),\n",
              " tensor([  9, 401, 174, 405, 216,  36, 197, 134,  53, 222, 343,  57, 171, 219,\n",
              "         150, 497,  62, 249, 243, 244, 158, 153, 388, 506, 221,  63, 479, 507,\n",
              "         194,  89, 232, 203, 355,  28, 152, 282, 526, 229, 340,  90, 515, 296,\n",
              "         120, 462, 146,  71, 493, 242, 147, 417,  97, 470,  82,  86, 213,  31,\n",
              "         421, 492, 525, 315, 310, 408,  45, 139,  68, 269, 288, 184, 448, 321,\n",
              "         129, 438, 509, 164,  56, 188,  55, 107, 323, 409, 471, 337, 113, 391,\n",
              "         100, 294, 311, 431, 468, 253,  50, 176, 297, 299, 364, 234, 389, 495,\n",
              "         259,  65, 356, 484, 122,  18,  35, 453, 394, 434,  76]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_area = area[train_indices]\n",
        "train_bedrooms = bedrooms[train_indices]\n",
        "train_bathrooms = bathrooms[train_indices]\n",
        "train_stories = stories[train_indices]\n",
        "train_parking = parking[train_indices]\n",
        "\n",
        "train_data = data_normalized[train_indices]\n",
        "train_price = target_normalized[train_indices]\n",
        "\n",
        "eval_area = area[val_indices]\n",
        "eval_bedrooms = bedrooms[val_indices]\n",
        "eval_bathrooms = bathrooms[val_indices]\n",
        "eval_stories = stories[val_indices]\n",
        "eval_parking = parking[val_indices]\n",
        "\n",
        "eval_data = data_normalized[val_indices]\n",
        "eval_price = target_normalized[val_indices]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4M8trgDFBseZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(area, bedrooms, bathrooms, stories, parking, w1, w2, w3, w4, w5, b):\n",
        "  return w5 * area + w4 * bedrooms + w3 * bathrooms + w2 * stories + w1 * parking + b"
      ],
      "metadata": {
        "id": "pgUU99t2C-Kh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(price_pred, target_normalized):\n",
        "  squared_diffs = (price_pred - target_normalized)**2\n",
        "  return squared_diffs.mean()"
      ],
      "metadata": {
        "id": "fRMhMhSLEci0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.SGD([params], lr=learning_rate)"
      ],
      "metadata": {
        "id": "1YegQL2KEc7i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_pred = model(area, bedrooms, bathrooms, stories, parking, *params)\n",
        "loss = loss_fn(price_pred, target_normalized)\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgdOgq1zEgHv",
        "outputId": "f77d40c3-4800-4d30-9630-50219199e6e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9998e-01, 3.0920e-12],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "price_train = model(train_area, train_bedrooms, train_bathrooms, train_stories, train_parking, *params)\n",
        "train_loss = loss_fn(price_train, train_price)\n",
        "\n",
        "price_eval = model(eval_area, eval_bedrooms, eval_bathrooms, eval_stories, eval_parking, *params)\n",
        "eval_loss = loss_fn(price_eval, eval_price)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "train_loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIgIw2O2EjtM",
        "outputId": "0829889d-251d-4527-9bb2-f9a61d60605a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9738, 0.9702, 0.9700, 0.9660, 0.9762, 0.0015], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_area, train_bedrooms, train_bathrooms, train_stories, train_parking, train_price,\n",
        "                  eval_area, eval_bedrooms, eval_bathrooms, eval_stories, eval_parking, eval_price):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    price_train = model(train_area, train_bedrooms, train_bathrooms, train_stories, train_parking, *params)\n",
        "    train_loss = loss_fn(price_train, train_price)\n",
        "\n",
        "    price_eval = model(eval_area, eval_bedrooms, eval_bathrooms, eval_stories, eval_parking, *params)\n",
        "    eval_loss = loss_fn(price_eval, eval_price)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch <= 3 or epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "        f\" Validation loss {eval_loss.item():.4f}\")\n",
        "  \n",
        "  return params"
      ],
      "metadata": {
        "id": "UHjTYhLhEpfH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.b\n",
        "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = .001\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 5000,\n",
        "  optimizer = optimizer,\n",
        "  params = params,\n",
        "  train_area = train_area,\n",
        "  train_bedrooms = train_bedrooms,\n",
        "  train_bathrooms = train_bathrooms,\n",
        "  train_stories = train_stories,\n",
        "  train_parking = train_parking,\n",
        "  train_price = train_price,\n",
        "  eval_area = eval_area,\n",
        "  eval_bedrooms = eval_bedrooms,\n",
        "  eval_bathrooms = eval_bathrooms,\n",
        "  eval_stories = eval_stories,\n",
        "  eval_parking = eval_parking,\n",
        "  eval_price = eval_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODYaFdUFEt-N",
        "outputId": "a0aa0a3b-c5a7-43cf-a4f6-5bd66ee339a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 5.9623, Validation loss 6.3801\n",
            "Epoch 2, Training loss 5.9204, Validation loss 6.3363\n",
            "Epoch 3, Training loss 5.8788, Validation loss 6.2928\n",
            "Epoch 500, Training loss 0.5919, Validation loss 0.5656\n",
            "Epoch 1000, Training loss 0.4671, Validation loss 0.3699\n",
            "Epoch 1500, Training loss 0.4624, Validation loss 0.3547\n",
            "Epoch 2000, Training loss 0.4618, Validation loss 0.3531\n",
            "Epoch 2500, Training loss 0.4616, Validation loss 0.3531\n",
            "Epoch 3000, Training loss 0.4616, Validation loss 0.3533\n",
            "Epoch 3500, Training loss 0.4616, Validation loss 0.3535\n",
            "Epoch 4000, Training loss 0.4616, Validation loss 0.3536\n",
            "Epoch 4500, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 5000, Training loss 0.4616, Validation loss 0.3537\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1920, 0.2216, 0.3334, 0.0861, 0.3880, 0.0123], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "linear_model = nn.Linear(5, 1)\n",
        "linear_model(data_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKZN__zLG3wT",
        "outputId": "5ed72996-0da1-4039-ecea-28d9870e0837"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.3132e-01],\n",
              "        [ 2.8802e+00],\n",
              "        [ 8.3531e-01],\n",
              "        [ 9.4112e-01],\n",
              "        [-2.1493e-01],\n",
              "        [ 1.5236e+00],\n",
              "        [ 1.7557e+00],\n",
              "        [-1.0937e+00],\n",
              "        [-2.8639e-01],\n",
              "        [ 1.4678e+00],\n",
              "        [-2.4321e-01],\n",
              "        [ 1.4103e+00],\n",
              "        [ 1.8808e-01],\n",
              "        [ 9.3506e-01],\n",
              "        [ 2.0944e-01],\n",
              "        [-6.5692e-02],\n",
              "        [ 1.8282e-01],\n",
              "        [ 1.6052e+00],\n",
              "        [ 1.3986e+00],\n",
              "        [ 7.8091e-01],\n",
              "        [ 6.9004e-01],\n",
              "        [ 8.2187e-01],\n",
              "        [-4.3664e-01],\n",
              "        [ 9.7639e-01],\n",
              "        [ 9.5722e-01],\n",
              "        [ 6.1557e-01],\n",
              "        [ 1.0151e+00],\n",
              "        [-5.2334e-01],\n",
              "        [-1.1179e-01],\n",
              "        [ 2.9843e-01],\n",
              "        [ 1.7129e+00],\n",
              "        [ 1.0249e+00],\n",
              "        [ 3.6359e-01],\n",
              "        [ 1.5673e+00],\n",
              "        [-1.1596e+00],\n",
              "        [ 1.7629e+00],\n",
              "        [ 9.7753e-01],\n",
              "        [ 9.7350e-01],\n",
              "        [ 1.1299e+00],\n",
              "        [ 8.6234e-01],\n",
              "        [-3.9720e-01],\n",
              "        [ 9.7724e-01],\n",
              "        [ 1.8175e+00],\n",
              "        [ 1.2888e+00],\n",
              "        [ 8.6234e-01],\n",
              "        [ 7.0684e-01],\n",
              "        [ 1.4415e+00],\n",
              "        [ 1.4933e+00],\n",
              "        [ 1.0037e+00],\n",
              "        [-6.0961e-02],\n",
              "        [ 1.2902e+00],\n",
              "        [ 6.6935e-01],\n",
              "        [ 8.6234e-01],\n",
              "        [ 1.9573e+00],\n",
              "        [ 8.2505e-01],\n",
              "        [ 8.7039e-02],\n",
              "        [-1.0639e+00],\n",
              "        [ 5.4706e-01],\n",
              "        [ 6.8578e-01],\n",
              "        [ 1.4415e+00],\n",
              "        [ 8.2505e-01],\n",
              "        [ 5.5303e-02],\n",
              "        [ 2.2066e-01],\n",
              "        [ 9.4272e-01],\n",
              "        [-7.6506e-01],\n",
              "        [ 5.2238e-01],\n",
              "        [-3.9871e-01],\n",
              "        [ 7.6460e-01],\n",
              "        [-2.2119e-01],\n",
              "        [ 3.2289e-02],\n",
              "        [ 6.0880e-01],\n",
              "        [ 4.3590e-01],\n",
              "        [ 3.8006e-01],\n",
              "        [ 1.5312e+00],\n",
              "        [ 2.9303e-01],\n",
              "        [ 2.3035e-03],\n",
              "        [ 6.6270e-01],\n",
              "        [ 6.5430e-01],\n",
              "        [ 2.3678e-01],\n",
              "        [ 7.0684e-01],\n",
              "        [ 8.7039e-02],\n",
              "        [ 1.0352e+00],\n",
              "        [ 4.3888e-02],\n",
              "        [ 1.0151e+00],\n",
              "        [ 7.4889e-01],\n",
              "        [ 4.7038e-01],\n",
              "        [-1.0158e-01],\n",
              "        [ 4.1964e-01],\n",
              "        [ 5.7062e-02],\n",
              "        [ 5.6001e-01],\n",
              "        [-2.3431e-01],\n",
              "        [ 7.0560e-01],\n",
              "        [ 1.1412e+00],\n",
              "        [ 1.2436e+00],\n",
              "        [ 8.6234e-01],\n",
              "        [ 1.7594e+00],\n",
              "        [-5.3648e-01],\n",
              "        [-2.6323e-01],\n",
              "        [ 6.4379e-01],\n",
              "        [-6.1034e-01],\n",
              "        [ 2.7319e-02],\n",
              "        [ 4.4782e-01],\n",
              "        [ 1.4941e+00],\n",
              "        [ 6.7006e-01],\n",
              "        [ 9.9581e-01],\n",
              "        [ 4.3471e-01],\n",
              "        [-4.3099e-01],\n",
              "        [-7.5309e-02],\n",
              "        [ 1.0616e-01],\n",
              "        [ 1.8124e-01],\n",
              "        [ 1.4219e-01],\n",
              "        [ 5.7243e-01],\n",
              "        [-1.1602e+00],\n",
              "        [-1.7520e-01],\n",
              "        [ 7.0034e-01],\n",
              "        [-4.9439e-03],\n",
              "        [-4.2094e-03],\n",
              "        [-6.7685e-01],\n",
              "        [-6.9178e-01],\n",
              "        [ 9.8050e-02],\n",
              "        [ 1.4850e-01],\n",
              "        [-4.6877e-01],\n",
              "        [-8.9049e-02],\n",
              "        [-3.1929e-01],\n",
              "        [ 1.3863e+00],\n",
              "        [-8.0367e-01],\n",
              "        [ 8.3336e-02],\n",
              "        [ 6.5430e-01],\n",
              "        [ 4.4782e-01],\n",
              "        [ 2.4789e-01],\n",
              "        [-5.2152e-01],\n",
              "        [-2.8403e-01],\n",
              "        [ 5.2908e-02],\n",
              "        [ 9.4946e-02],\n",
              "        [ 1.0015e-01],\n",
              "        [ 1.0151e+00],\n",
              "        [ 7.3538e-01],\n",
              "        [-3.4920e-01],\n",
              "        [ 7.3927e-02],\n",
              "        [ 1.6741e-01],\n",
              "        [ 1.0361e+00],\n",
              "        [ 1.7652e-01],\n",
              "        [-2.2705e-01],\n",
              "        [-3.2539e-01],\n",
              "        [-3.5551e-01],\n",
              "        [ 3.8216e-01],\n",
              "        [-1.1495e-01],\n",
              "        [ 8.7760e-01],\n",
              "        [-6.9003e-02],\n",
              "        [-5.5185e-01],\n",
              "        [-2.4860e-01],\n",
              "        [ 1.0246e-01],\n",
              "        [-1.4347e+00],\n",
              "        [ 1.4204e+00],\n",
              "        [ 1.4985e+00],\n",
              "        [ 9.3275e-01],\n",
              "        [-7.4222e-01],\n",
              "        [ 5.8040e-01],\n",
              "        [-2.8419e-03],\n",
              "        [ 3.8990e-01],\n",
              "        [-3.2418e-01],\n",
              "        [-4.1678e-02],\n",
              "        [-2.4362e-01],\n",
              "        [-7.3434e-01],\n",
              "        [ 7.5043e-01],\n",
              "        [ 4.3084e-02],\n",
              "        [ 1.6075e-02],\n",
              "        [ 1.6696e+00],\n",
              "        [-7.3571e-01],\n",
              "        [-2.3731e-01],\n",
              "        [ 1.4292e-01],\n",
              "        [-6.6985e-01],\n",
              "        [ 2.6125e-01],\n",
              "        [-4.1523e-01],\n",
              "        [ 3.1825e-01],\n",
              "        [ 2.7296e-01],\n",
              "        [-5.9593e-02],\n",
              "        [-6.5289e-01],\n",
              "        [ 9.1218e-02],\n",
              "        [ 1.5479e+00],\n",
              "        [ 5.2173e-01],\n",
              "        [-3.9075e-02],\n",
              "        [-6.7205e-02],\n",
              "        [-4.2928e-01],\n",
              "        [ 7.1390e-01],\n",
              "        [-2.4116e-02],\n",
              "        [-3.2880e-01],\n",
              "        [-6.5814e-01],\n",
              "        [ 2.6920e-01],\n",
              "        [ 1.9007e-01],\n",
              "        [-2.3384e-01],\n",
              "        [-8.3335e-01],\n",
              "        [-7.1069e-01],\n",
              "        [ 5.7651e-02],\n",
              "        [-1.3558e-01],\n",
              "        [ 1.5774e+00],\n",
              "        [-8.2483e-01],\n",
              "        [ 1.1614e+00],\n",
              "        [-3.3394e-01],\n",
              "        [ 2.7621e-01],\n",
              "        [-1.8386e-01],\n",
              "        [-1.3920e-01],\n",
              "        [ 5.5556e-01],\n",
              "        [-8.5552e-01],\n",
              "        [-5.1837e-01],\n",
              "        [ 1.7372e-01],\n",
              "        [-4.7444e-02],\n",
              "        [-2.4116e-02],\n",
              "        [ 2.8727e-01],\n",
              "        [-7.2330e-01],\n",
              "        [ 6.5578e-01],\n",
              "        [-5.1991e-01],\n",
              "        [ 9.4347e-01],\n",
              "        [-3.8317e-01],\n",
              "        [ 1.0494e-01],\n",
              "        [ 1.6221e-01],\n",
              "        [ 2.0104e-01],\n",
              "        [ 4.2289e-01],\n",
              "        [ 5.6075e-02],\n",
              "        [-4.4450e-01],\n",
              "        [ 3.3007e-01],\n",
              "        [ 9.0584e-02],\n",
              "        [ 4.5169e-01],\n",
              "        [ 5.3303e-02],\n",
              "        [ 3.3881e-01],\n",
              "        [ 1.1646e+00],\n",
              "        [ 3.6429e-01],\n",
              "        [ 3.5798e-01],\n",
              "        [ 7.6256e-01],\n",
              "        [-1.3951e-01],\n",
              "        [ 3.0283e-01],\n",
              "        [-4.7107e-01],\n",
              "        [-1.0241e-01],\n",
              "        [-4.5426e-01],\n",
              "        [ 1.4743e+00],\n",
              "        [ 1.2067e-01],\n",
              "        [ 5.6872e-01],\n",
              "        [-2.3536e-01],\n",
              "        [-2.3970e-02],\n",
              "        [ 2.9723e-01],\n",
              "        [ 3.1404e-01],\n",
              "        [ 4.4066e-01],\n",
              "        [-9.1377e-02],\n",
              "        [ 2.3177e-02],\n",
              "        [-2.6794e-01],\n",
              "        [ 5.8074e-01],\n",
              "        [-3.8700e-01],\n",
              "        [ 7.2499e-01],\n",
              "        [ 8.6923e-01],\n",
              "        [-7.4416e-02],\n",
              "        [ 2.3052e-01],\n",
              "        [ 3.5503e-01],\n",
              "        [-1.0533e+00],\n",
              "        [ 5.0041e-01],\n",
              "        [ 9.0900e-02],\n",
              "        [ 3.7006e-01],\n",
              "        [ 7.2367e-01],\n",
              "        [-8.8410e-01],\n",
              "        [ 2.9303e-01],\n",
              "        [ 3.2014e-01],\n",
              "        [ 3.8530e-01],\n",
              "        [-7.7714e-02],\n",
              "        [ 1.6800e-01],\n",
              "        [-1.2585e-01],\n",
              "        [ 3.5537e-01],\n",
              "        [-1.1504e-02],\n",
              "        [ 3.2295e-01],\n",
              "        [ 2.0054e-01],\n",
              "        [-8.0822e-01],\n",
              "        [-1.1870e-01],\n",
              "        [ 1.2909e+00],\n",
              "        [-1.0674e+00],\n",
              "        [ 4.0756e-01],\n",
              "        [ 1.9705e-01],\n",
              "        [-9.6587e-01],\n",
              "        [ 1.3836e-01],\n",
              "        [ 5.2613e-01],\n",
              "        [-1.0024e-01],\n",
              "        [ 7.8673e-01],\n",
              "        [-1.0630e-01],\n",
              "        [ 2.0194e-01],\n",
              "        [ 9.4206e-01],\n",
              "        [ 6.2588e-02],\n",
              "        [-7.4622e-01],\n",
              "        [ 1.7196e-01],\n",
              "        [-4.0771e-01],\n",
              "        [-3.0996e-01],\n",
              "        [-2.8685e-01],\n",
              "        [-2.3851e-01],\n",
              "        [ 8.0018e-01],\n",
              "        [ 9.1372e-01],\n",
              "        [-1.9176e-02],\n",
              "        [ 1.6131e-01],\n",
              "        [ 5.2508e-01],\n",
              "        [ 2.9628e-02],\n",
              "        [ 4.6823e-02],\n",
              "        [ 9.7218e-01],\n",
              "        [ 6.4663e-01],\n",
              "        [ 2.2627e-01],\n",
              "        [ 5.2659e-01],\n",
              "        [ 1.7072e-01],\n",
              "        [-7.8765e-02],\n",
              "        [ 8.0041e-01],\n",
              "        [-4.8999e-01],\n",
              "        [ 3.9522e-01],\n",
              "        [ 3.5503e-01],\n",
              "        [ 2.0895e-01],\n",
              "        [ 7.1526e-01],\n",
              "        [ 2.9240e-01],\n",
              "        [-7.7480e-01],\n",
              "        [-6.4606e-01],\n",
              "        [ 3.5167e-01],\n",
              "        [-3.9541e-01],\n",
              "        [ 6.4243e-01],\n",
              "        [ 8.7220e-01],\n",
              "        [-2.6425e-02],\n",
              "        [ 2.5639e-01],\n",
              "        [ 1.3574e+00],\n",
              "        [-4.7318e-01],\n",
              "        [ 5.5783e-01],\n",
              "        [ 6.9004e-01],\n",
              "        [ 1.5006e+00],\n",
              "        [ 7.8376e-01],\n",
              "        [ 6.9474e-01],\n",
              "        [-1.8176e-01],\n",
              "        [-6.5163e-01],\n",
              "        [-1.0271e+00],\n",
              "        [ 3.6593e-02],\n",
              "        [ 5.5625e-01],\n",
              "        [-1.2501e-01],\n",
              "        [ 4.4471e-01],\n",
              "        [ 1.2373e+00],\n",
              "        [-8.6603e-01],\n",
              "        [-2.4116e-02],\n",
              "        [ 6.4279e-01],\n",
              "        [ 1.0139e+00],\n",
              "        [-1.3352e-02],\n",
              "        [-8.3653e-02],\n",
              "        [ 4.7308e-01],\n",
              "        [ 1.1581e-01],\n",
              "        [-6.8617e-01],\n",
              "        [ 1.8188e+00],\n",
              "        [-4.6047e-01],\n",
              "        [ 1.3332e-01],\n",
              "        [ 1.5749e-01],\n",
              "        [ 7.9403e-02],\n",
              "        [ 6.4165e-01],\n",
              "        [-6.0899e-02],\n",
              "        [ 9.6907e-01],\n",
              "        [-2.1539e-01],\n",
              "        [ 9.3736e-01],\n",
              "        [ 1.8377e-01],\n",
              "        [ 8.0228e-01],\n",
              "        [ 2.9925e-01],\n",
              "        [ 1.0575e-01],\n",
              "        [-3.1218e-02],\n",
              "        [-2.7579e-01],\n",
              "        [-5.8987e-01],\n",
              "        [ 1.9638e-01],\n",
              "        [ 3.1035e-02],\n",
              "        [ 1.3752e-01],\n",
              "        [-6.4974e-01],\n",
              "        [ 1.3647e-01],\n",
              "        [ 1.8545e-01],\n",
              "        [-3.6727e-02],\n",
              "        [-1.0661e-02],\n",
              "        [ 1.8061e-01],\n",
              "        [ 1.8061e-01],\n",
              "        [-3.0629e-02],\n",
              "        [ 1.8377e-01],\n",
              "        [ 9.6518e-01],\n",
              "        [-8.4020e-02],\n",
              "        [-4.3033e-02],\n",
              "        [ 5.5506e-01],\n",
              "        [ 9.3018e-01],\n",
              "        [-3.3520e-01],\n",
              "        [ 1.4480e+00],\n",
              "        [ 7.2966e-01],\n",
              "        [ 3.6031e-01],\n",
              "        [ 4.6588e-01],\n",
              "        [ 8.9180e-02],\n",
              "        [ 1.4173e-01],\n",
              "        [-3.9880e-02],\n",
              "        [ 8.2996e-01],\n",
              "        [ 8.9180e-02],\n",
              "        [ 1.7956e-01],\n",
              "        [ 4.3120e-01],\n",
              "        [-1.5443e-01],\n",
              "        [-9.2428e-02],\n",
              "        [-7.7144e-01],\n",
              "        [ 8.0480e-01],\n",
              "        [-2.7899e-02],\n",
              "        [-1.2816e-01],\n",
              "        [-7.9729e-01],\n",
              "        [-3.8279e-01],\n",
              "        [-1.3982e+00],\n",
              "        [ 6.0600e-01],\n",
              "        [ 3.6849e-01],\n",
              "        [ 3.8971e-01],\n",
              "        [ 2.1610e-01],\n",
              "        [ 6.1945e-01],\n",
              "        [ 5.7209e-01],\n",
              "        [-5.5852e-02],\n",
              "        [-1.3774e+00],\n",
              "        [-2.2380e-01],\n",
              "        [-3.3865e-01],\n",
              "        [ 4.2944e-01],\n",
              "        [ 3.7397e-01],\n",
              "        [ 1.4173e-01],\n",
              "        [ 1.0803e+00],\n",
              "        [-4.2168e-01],\n",
              "        [ 3.7397e-01],\n",
              "        [ 1.6871e-02],\n",
              "        [ 8.2425e-01],\n",
              "        [ 1.3752e-01],\n",
              "        [ 2.1473e-01],\n",
              "        [ 4.7324e-01],\n",
              "        [ 1.7956e-01],\n",
              "        [ 1.9705e-01],\n",
              "        [-5.0104e-01],\n",
              "        [ 4.3735e-01],\n",
              "        [ 6.2906e-02],\n",
              "        [ 1.7115e-01],\n",
              "        [-4.1117e-01],\n",
              "        [-3.4625e-02],\n",
              "        [ 1.0803e+00],\n",
              "        [-3.0082e-01],\n",
              "        [ 6.5741e-02],\n",
              "        [ 5.6396e-01],\n",
              "        [-7.8983e-01],\n",
              "        [ 2.9937e-01],\n",
              "        [-6.2220e-01],\n",
              "        [-6.5394e-01],\n",
              "        [-2.2729e-01],\n",
              "        [-6.8652e-01],\n",
              "        [ 1.3752e-01],\n",
              "        [ 6.5741e-02],\n",
              "        [-2.0858e-01],\n",
              "        [ 8.9180e-02],\n",
              "        [ 1.4908e-01],\n",
              "        [-6.7055e-01],\n",
              "        [-1.6810e-01],\n",
              "        [ 7.0647e-01],\n",
              "        [-4.4634e-02],\n",
              "        [-3.6727e-02],\n",
              "        [ 7.7870e-01],\n",
              "        [ 1.3077e+00],\n",
              "        [ 1.9428e-01],\n",
              "        [ 9.8463e-01],\n",
              "        [ 1.1776e-01],\n",
              "        [-7.1409e-02],\n",
              "        [-1.4728e-01],\n",
              "        [ 1.9819e-01],\n",
              "        [ 6.6601e-01],\n",
              "        [-1.8176e-01],\n",
              "        [-5.9456e-01],\n",
              "        [-2.6908e-01],\n",
              "        [-3.3235e-01],\n",
              "        [-1.1345e-01],\n",
              "        [ 1.9428e-01],\n",
              "        [ 1.3728e-01],\n",
              "        [ 4.0836e-02],\n",
              "        [ 6.4164e-02],\n",
              "        [ 2.3736e-01],\n",
              "        [ 8.2385e-01],\n",
              "        [ 1.6275e-01],\n",
              "        [-3.3574e-02],\n",
              "        [ 8.0354e-01],\n",
              "        [ 2.6416e-01],\n",
              "        [ 7.8670e-02],\n",
              "        [-5.5053e-01],\n",
              "        [-1.0294e-01],\n",
              "        [ 6.0982e-01],\n",
              "        [-2.8391e-01],\n",
              "        [-3.1894e-01],\n",
              "        [ 5.5506e-01],\n",
              "        [ 1.0280e-01],\n",
              "        [ 4.0836e-02],\n",
              "        [ 3.3927e-01],\n",
              "        [-6.7265e-01],\n",
              "        [ 3.5188e-01],\n",
              "        [ 2.7835e-01],\n",
              "        [-3.9880e-02],\n",
              "        [-4.0404e-01],\n",
              "        [ 2.4262e-01],\n",
              "        [ 1.8061e-01],\n",
              "        [-6.8463e-02],\n",
              "        [-8.5552e-01],\n",
              "        [-5.2626e-01],\n",
              "        [ 3.7080e-01],\n",
              "        [ 2.6045e-01],\n",
              "        [ 7.1110e-01],\n",
              "        [ 4.3911e-01],\n",
              "        [-4.3324e-01],\n",
              "        [-1.5254e-01],\n",
              "        [ 2.9723e-01],\n",
              "        [ 1.4173e-01],\n",
              "        [ 1.4866e-01],\n",
              "        [ 6.6015e-01],\n",
              "        [ 1.3857e+00],\n",
              "        [-3.1133e-01],\n",
              "        [-2.7244e-01],\n",
              "        [ 6.2282e-01],\n",
              "        [-4.3744e-01],\n",
              "        [ 2.2738e-01],\n",
              "        [-1.2921e-01],\n",
              "        [ 2.5628e-01],\n",
              "        [ 1.8377e-01],\n",
              "        [ 9.9689e-02],\n",
              "        [ 1.6565e+00],\n",
              "        [-3.1974e-01],\n",
              "        [-3.5127e-01],\n",
              "        [ 5.5506e-01],\n",
              "        [-1.7125e-01],\n",
              "        [-2.4116e-02],\n",
              "        [-4.6186e-02],\n",
              "        [ 6.4804e-01],\n",
              "        [ 6.7326e-01],\n",
              "        [ 1.9428e-01],\n",
              "        [ 3.6168e-01],\n",
              "        [-2.4713e-01],\n",
              "        [ 1.8009e-01],\n",
              "        [ 3.1059e-02],\n",
              "        [ 1.5711e-01],\n",
              "        [ 2.1908e-01],\n",
              "        [ 1.7956e-01],\n",
              "        [ 2.2791e-01],\n",
              "        [ 3.6915e-01],\n",
              "        [ 7.2405e-01],\n",
              "        [-1.2606e-01],\n",
              "        [-2.2200e-01],\n",
              "        [-5.7407e-01],\n",
              "        [ 2.4682e-01],\n",
              "        [ 3.8941e-02],\n",
              "        [-6.0329e-01],\n",
              "        [ 6.3543e-01],\n",
              "        [-1.2266e+00],\n",
              "        [ 1.1251e-01],\n",
              "        [ 1.7862e-01],\n",
              "        [ 6.7431e-01],\n",
              "        [ 1.0997e+00],\n",
              "        [-2.6929e-01],\n",
              "        [ 1.8166e-01],\n",
              "        [-3.2289e-01],\n",
              "        [-1.1345e-01]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVQ-KOL1LXNQ",
        "outputId": "ac450da4-9ec2-400d-f2ef-498cf1937a35"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.2281, -0.4275,  0.3708,  0.2674,  0.3674]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY47zxPALyQM",
        "outputId": "a4a1188d-5156-4b0d-dea5-a283fb6ba4a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.2171], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5)\n",
        "linear_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVGgQcSyL0ok",
        "outputId": "1357886e-1536-4325-d2d9-6a94656a5c97"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5672], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(10, 5)\n",
        "linear_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxLpnpAANGPh",
        "outputId": "0bbd9f93-7198-49a1-e28f-944274c150f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672],\n",
              "        [0.5672]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_normalized = torch.tensor(data_normalized).unsqueeze(1)\n",
        "target_normalized = torch.tensor(target_normalized).unsqueeze(1)\n",
        "\n",
        "\n",
        "data_normalized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBxmuKSeNQ9n",
        "outputId": "9c152d05-939b-46c6-f24f-786c113b4299"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([545, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_normalized.shape\n",
        "\n",
        "train_price = torch.tensor(train_price).unsqueeze(1)\n",
        "\n",
        "eval_price = torch.tensor(eval_price).unsqueeze(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOS8TuyyPJwI",
        "outputId": "28b792e6-5496-460f-9ff6-e0fb689520e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_normalized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZHhEIoS2Kvc",
        "outputId": "50f4e2bc-bea2-4b96-cb4e-661d9f1f5fc2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([545, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_price.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86iR8w4SjV55",
        "outputId": "0cca0d7d-fd4c-44f2-ca66-f2137868519d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([109, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(5, 1)\n",
        "optimizer = optim.SGD(\n",
        "  linear_model.parameters(),\n",
        "  lr=1e-2)"
      ],
      "metadata": {
        "id": "AqYHvQFJP2MM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1z-TV-kQDTu",
        "outputId": "a2b37646-ec74-4c5a-8f8e-deab761f8adf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f21d8c99e50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(linear_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_C5F8lQQGrp",
        "outputId": "c42abe79-af99-4bb4-eea2-167b62457360"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.3330, -0.2801,  0.3444,  0.2206,  0.0361]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.3689], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_data, train_price,\n",
        "                  eval_data, eval_price):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    price_train = model(train_data)\n",
        "    train_loss = loss_fn(price_train, train_price)\n",
        "\n",
        "    price_eval = model(eval_data)\n",
        "    eval_loss = loss_fn(price_eval, eval_price)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch == 1 or epoch % 50 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "            f\" Validation loss {eval_loss.item():.4f}\")\n"
      ],
      "metadata": {
        "id": "abIfh04sQLXv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(5, 1)\n",
        "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 3000,\n",
        "  optimizer = optimizer,\n",
        "  model = linear_model,\n",
        "  loss_fn = nn.MSELoss(),\n",
        "  train_data = train_data,\n",
        "  train_price = train_price,\n",
        "  eval_data = eval_data,\n",
        "  eval_price = eval_price)\n",
        "\n",
        "print()\n",
        "print(linear_model.weight)\n",
        "print(linear_model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0u1VtgwSsEL",
        "outputId": "af1973bc-17cf-44e0-8ff0-ac55db4dbf25"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 1.8364, Validation loss 1.3323\n",
            "Epoch 50, Training loss 0.5587, Validation loss 0.3374\n",
            "Epoch 100, Training loss 0.4729, Validation loss 0.3298\n",
            "Epoch 150, Training loss 0.4635, Validation loss 0.3426\n",
            "Epoch 200, Training loss 0.4620, Validation loss 0.3486\n",
            "Epoch 250, Training loss 0.4617, Validation loss 0.3512\n",
            "Epoch 300, Training loss 0.4616, Validation loss 0.3525\n",
            "Epoch 350, Training loss 0.4616, Validation loss 0.3531\n",
            "Epoch 400, Training loss 0.4616, Validation loss 0.3534\n",
            "Epoch 450, Training loss 0.4616, Validation loss 0.3535\n",
            "Epoch 500, Training loss 0.4616, Validation loss 0.3536\n",
            "Epoch 550, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 600, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 650, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 700, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 750, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 800, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 850, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 900, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 950, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1000, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1050, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1100, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1150, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1200, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1250, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1300, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1350, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1400, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1450, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1500, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1550, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1600, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1650, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1700, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1750, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1800, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1850, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1900, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 1950, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2000, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2050, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2100, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2150, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2200, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2250, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2300, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2350, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2400, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2450, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2500, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2550, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2600, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2650, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2700, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2750, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2800, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2850, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2900, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 2950, Training loss 0.4616, Validation loss 0.3537\n",
            "Epoch 3000, Training loss 0.4616, Validation loss 0.3537\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[0.3880, 0.0860, 0.3336, 0.2215, 0.1918]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0123], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = nn.Sequential(\n",
        "            nn.Linear(1, 13),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(13, 1))\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4BxYSxgS-tC",
        "outputId": "83cc9269-3e25-4cbf-d22c-a642c20c517e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[param.shape for param in seq_model.parameters()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLwJI8W1Uv3L",
        "outputId": "3344d851-1769-42b1-a690-f41c8b769857"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgdUSpBoU5is",
        "outputId": "efc50fa1-bbae-41c9-850f-dec2c1a4344d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([13, 1])\n",
            "0.bias torch.Size([13])\n",
            "2.weight torch.Size([1, 13])\n",
            "2.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "seq_model = nn.Sequential(OrderedDict([\n",
        "  ('hidden_linear', nn.Linear(5, 8)),\n",
        "  ('hidden_activation', nn.Tanh()),\n",
        "  ('hidden_linear2', nn.Linear(8, 8)),\n",
        "  ('hidden_activation2', nn.Tanh()),\n",
        "  ('output_linear', nn.Linear(8, 1)),\n",
        "]))\n",
        "\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "degPACFQVIDC",
        "outputId": "29d34a27-4839-4100-dc02-ff78817e27f5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (hidden_linear2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (hidden_activation2): Tanh()\n",
              "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_ky7hluVeRr",
        "outputId": "b69d3dfc-2b6c-4deb-e494-9a573e0df103"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_linear.weight torch.Size([8, 5])\n",
            "hidden_linear.bias torch.Size([8])\n",
            "hidden_linear2.weight torch.Size([8, 8])\n",
            "hidden_linear2.bias torch.Size([8])\n",
            "output_linear.weight torch.Size([1, 8])\n",
            "output_linear.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model.output_linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0qYIOZnVirC",
        "outputId": "b591fed7-4634-4d0a-bd15-d9909ca89d03"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.3264], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##train_price_fixed = train_price.clone().detach()\n",
        "#train_price_fixed.shape\n",
        "train_price = torch.tensor(train_price).squeeze(1)\n",
        "train_price = torch.tensor(train_price).unsqueeze(1)\n",
        "train_price.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNM0IVq2de1F",
        "outputId": "4c1e4a1b-621e-4ebe-86ae-e43af38bcc45"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([436, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_price = torch.tensor(eval_price).squeeze(1)\n",
        "eval_price = torch.tensor(eval_price).unsqueeze(1)\n",
        "eval_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxTTsYUtd8Zs",
        "outputId": "60ebf230-22e3-468e-f579-c4ec60c3eed9"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([109, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "  n_epochs = 200,\n",
        "  optimizer = optimizer,\n",
        "  model = seq_model,\n",
        "  loss_fn = nn.MSELoss(),\n",
        "  train_data = train_data,\n",
        "  train_price = train_price,\n",
        "  eval_data = eval_data,\n",
        "  eval_price = eval_price)\n",
        "\n",
        "  #return F.mse_loss(input, target, reduction=self.reduction)\n",
        "print('output', seq_model(eval_data))\n",
        "print('answer', eval_price)\n",
        "print('hidden', seq_model.hidden_linear.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7CqRxRjVoB1",
        "outputId": "37a5cb81-ed33-4e80-80cd-ee13d9924ff1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 0.9533, Validation loss 0.6652\n",
            "Epoch 50, Training loss 0.6395, Validation loss 0.4095\n",
            "Epoch 100, Training loss 0.5235, Validation loss 0.3386\n",
            "Epoch 150, Training loss 0.4982, Validation loss 0.3387\n",
            "Epoch 200, Training loss 0.4918, Validation loss 0.3415\n",
            "output tensor([[ 1.2026],\n",
            "        [ 1.1263],\n",
            "        [-0.3203],\n",
            "        [-0.8566],\n",
            "        [ 0.1454],\n",
            "        [ 1.2781],\n",
            "        [ 0.2238],\n",
            "        [ 0.3888],\n",
            "        [ 1.2840],\n",
            "        [ 0.5316],\n",
            "        [-0.9472],\n",
            "        [ 1.4317],\n",
            "        [ 0.8168],\n",
            "        [ 0.1698],\n",
            "        [-0.2805],\n",
            "        [-0.9684],\n",
            "        [ 0.9769],\n",
            "        [ 0.5250],\n",
            "        [-0.6936],\n",
            "        [-0.2401],\n",
            "        [ 0.6033],\n",
            "        [ 0.7582],\n",
            "        [-0.5531],\n",
            "        [-1.0901],\n",
            "        [ 0.2595],\n",
            "        [ 1.2853],\n",
            "        [-0.2987],\n",
            "        [-1.0132],\n",
            "        [ 0.8806],\n",
            "        [ 1.3809],\n",
            "        [-0.5386],\n",
            "        [-0.0577],\n",
            "        [ 0.6547],\n",
            "        [ 1.2366],\n",
            "        [ 0.0747],\n",
            "        [-0.7315],\n",
            "        [-1.0623],\n",
            "        [ 1.3559],\n",
            "        [ 0.5149],\n",
            "        [-0.3095],\n",
            "        [-0.6151],\n",
            "        [ 0.6509],\n",
            "        [ 0.2751],\n",
            "        [-0.7329],\n",
            "        [ 0.5227],\n",
            "        [ 0.9766],\n",
            "        [-0.7563],\n",
            "        [-0.5546],\n",
            "        [ 0.8420],\n",
            "        [-1.0081],\n",
            "        [-0.0338],\n",
            "        [-0.5855],\n",
            "        [ 1.2211],\n",
            "        [ 0.3418],\n",
            "        [ 0.3808],\n",
            "        [ 1.0172],\n",
            "        [-0.8365],\n",
            "        [-0.5280],\n",
            "        [-1.0081],\n",
            "        [-0.6649],\n",
            "        [-0.4026],\n",
            "        [-0.9590],\n",
            "        [ 0.9166],\n",
            "        [ 0.2290],\n",
            "        [-0.1388],\n",
            "        [-0.5142],\n",
            "        [-0.3010],\n",
            "        [ 0.0228],\n",
            "        [-0.4462],\n",
            "        [ 0.6412],\n",
            "        [ 1.2735],\n",
            "        [-0.8804],\n",
            "        [ 0.1971],\n",
            "        [ 1.0464],\n",
            "        [ 1.2590],\n",
            "        [-0.3127],\n",
            "        [ 0.2079],\n",
            "        [ 0.2847],\n",
            "        [ 0.2279],\n",
            "        [-0.6452],\n",
            "        [-0.5379],\n",
            "        [-0.0043],\n",
            "        [ 0.8651],\n",
            "        [-0.6374],\n",
            "        [ 0.5799],\n",
            "        [ 0.3503],\n",
            "        [-0.2731],\n",
            "        [-0.3480],\n",
            "        [-1.0973],\n",
            "        [-0.7852],\n",
            "        [ 1.3424],\n",
            "        [ 0.7027],\n",
            "        [ 0.1635],\n",
            "        [ 0.5947],\n",
            "        [-0.6267],\n",
            "        [ 0.6975],\n",
            "        [-0.1818],\n",
            "        [-0.2782],\n",
            "        [-0.2001],\n",
            "        [ 1.2690],\n",
            "        [ 0.3105],\n",
            "        [-1.0771],\n",
            "        [ 0.8008],\n",
            "        [ 0.8474],\n",
            "        [ 1.4099],\n",
            "        [-0.9000],\n",
            "        [-0.8134],\n",
            "        [-0.2840],\n",
            "        [ 0.9898]], grad_fn=<AddmmBackward0>)\n",
            "answer tensor([[ 2.6910e+00],\n",
            "        [-6.7724e-01],\n",
            "        [ 2.5837e-01],\n",
            "        [-6.9595e-01],\n",
            "        [ 3.3827e-02],\n",
            "        [ 1.7516e+00],\n",
            "        [ 1.0119e-01],\n",
            "        [ 5.5403e-01],\n",
            "        [ 1.3811e+00],\n",
            "        [-3.5978e-03],\n",
            "        [-4.9011e-01],\n",
            "        [ 1.3250e+00],\n",
            "        [ 2.5837e-01],\n",
            "        [ 1.5114e-02],\n",
            "        [ 4.4549e-01],\n",
            "        [-1.1263e+00],\n",
            "        [ 1.2314e+00],\n",
            "        [-1.1961e-01],\n",
            "        [-1.1587e-01],\n",
            "        [-1.1587e-01],\n",
            "        [ 3.8936e-01],\n",
            "        [ 4.0807e-01],\n",
            "        [-6.7724e-01],\n",
            "        [-1.1563e+00],\n",
            "        [ 1.4462e-04],\n",
            "        [ 1.2127e+00],\n",
            "        [-9.7663e-01],\n",
            "        [-1.1638e+00],\n",
            "        [ 1.2739e-01],\n",
            "        [ 8.9459e-01],\n",
            "        [-5.9734e-02],\n",
            "        [ 7.1251e-02],\n",
            "        [-5.3128e-01],\n",
            "        [ 1.9425e+00],\n",
            "        [ 4.2678e-01],\n",
            "        [-2.6557e-01],\n",
            "        [-1.3135e+00],\n",
            "        [-4.1022e-02],\n",
            "        [-4.9011e-01],\n",
            "        [ 8.9459e-01],\n",
            "        [-1.2386e+00],\n",
            "        [-3.0299e-01],\n",
            "        [ 6.3262e-01],\n",
            "        [-9.0178e-01],\n",
            "        [ 4.4549e-01],\n",
            "        [ 1.0630e+00],\n",
            "        [-1.0515e+00],\n",
            "        [-1.1587e-01],\n",
            "        [ 4.4549e-01],\n",
            "        [-7.3337e-01],\n",
            "        [ 8.1974e-01],\n",
            "        [-9.3921e-01],\n",
            "        [ 9.8815e-01],\n",
            "        [ 9.3201e-01],\n",
            "        [ 6.7508e-02],\n",
            "        [ 1.9425e+00],\n",
            "        [-7.5208e-01],\n",
            "        [-1.0515e+00],\n",
            "        [-1.2947e+00],\n",
            "        [-3.5913e-01],\n",
            "        [-3.4042e-01],\n",
            "        [-7.1466e-01],\n",
            "        [ 1.4934e+00],\n",
            "        [ 5.2034e-01],\n",
            "        [ 1.1191e+00],\n",
            "        [-2.0943e-01],\n",
            "        [-3.0299e-01],\n",
            "        [ 1.8352e-01],\n",
            "        [-8.6436e-01],\n",
            "        [-3.9655e-01],\n",
            "        [ 5.9145e-01],\n",
            "        [-8.0822e-01],\n",
            "        [-1.1638e+00],\n",
            "        [ 3.3322e-01],\n",
            "        [ 1.3774e+00],\n",
            "        [ 1.6481e-01],\n",
            "        [ 1.3811e+00],\n",
            "        [ 7.2618e-01],\n",
            "        [-3.9655e-01],\n",
            "        [-7.1466e-01],\n",
            "        [-9.3921e-01],\n",
            "        [-4.5269e-01],\n",
            "        [ 7.0372e-01],\n",
            "        [-6.7724e-01],\n",
            "        [ 7.8231e-01],\n",
            "        [-3.0299e-01],\n",
            "        [-3.4416e-01],\n",
            "        [-7.8951e-01],\n",
            "        [-9.3921e-01],\n",
            "        [-1.3458e-01],\n",
            "        [ 1.4185e+00],\n",
            "        [ 2.5837e-01],\n",
            "        [-3.0299e-01],\n",
            "        [-3.0299e-01],\n",
            "        [-5.6871e-01],\n",
            "        [-7.8447e-02],\n",
            "        [-6.7724e-01],\n",
            "        [-1.0889e+00],\n",
            "        [-1.5704e-01],\n",
            "        [ 1.1566e+00],\n",
            "        [-5.3128e-01],\n",
            "        [-1.0141e+00],\n",
            "        [ 6.3262e-01],\n",
            "        [ 2.2044e+00],\n",
            "        [ 1.7719e+00],\n",
            "        [-8.6436e-01],\n",
            "        [-6.7724e-01],\n",
            "        [-7.8951e-01],\n",
            "        [ 1.0069e+00]])\n",
            "hidden tensor([[ 0.0031,  0.0029, -0.0005,  0.0010,  0.0009],\n",
            "        [-0.0112, -0.0018,  0.0296, -0.0092,  0.0039],\n",
            "        [ 0.0012,  0.0164,  0.0027, -0.0059,  0.0055],\n",
            "        [-0.0009, -0.0092,  0.0039, -0.0069, -0.0127],\n",
            "        [-0.0044,  0.0102,  0.0056,  0.0028,  0.0007],\n",
            "        [ 0.0072,  0.0037,  0.0034,  0.0061, -0.0032],\n",
            "        [-0.0012,  0.0002, -0.0004,  0.0009,  0.0011],\n",
            "        [ 0.0006,  0.0018,  0.0085,  0.0034,  0.0029]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IR5y7ZKmVq_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
